<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE topic PUBLIC "-//OASIS//DTD DITA Topic//EN" "topic.dtd">
<topic id="topic_10">
  <title>Chapter 9: Security, Privacy, and Sandboxing</title>
  <body>
    <section><title>Table of Contents</title></section>
    <ul>
      <li>
        9.1 Security Overview
      </li>
      <li>
        9.2 Sandboxed Execution
      </li>
      <li>
        9.3 Credential Management
      </li>
      <li>
        9.4 Input Validation and Sanitization
      </li>
      <li>
        9.5 Rate Limiting and Quotas
      </li>
      <li>
        9.6 Privacy-Preserving AI Interactions
      </li>
      <li>
        9.7 Audit Logging and Compliance
      </li>
      <li>
        9.8 Security Best Practices
      </li>
      <li>
        Exercises
      </li>
      <li>
        Summary
      </li>
    </ul>
    <section><title>9.1 Security Overview</title></section>
    <p>AI coding assistants have significant power over your codebase and infrastructure. Without proper security controls, they can:</p>
    <ul>
      <li>
        Execute arbitrary commands
      </li>
      <li>
        Access sensitive files and credentials
      </li>
      <li>
        Modify or delete critical code
      </li>
      <li>
        Expose private data to AI providers
      </li>
      <li>
        Exceed budget limits
      </li>
      <li>
        Violate compliance requirements
      </li>
    </ul>
    <p>This chapter builds comprehensive security controls to make your AI assistant safe for production use.</p>
    <section><title>Threat Model</title></section>
    <codeblock outputclass="language-typescript">/**
 * Security threats for AI coding assistants
 */
export enum ThreatCategory {
  /** Unauthorized access to files, credentials, or systems */
  UNAUTHORIZED_ACCESS = &apos;unauthorized_access&apos;,

  /** Execution of destructive operations */
  DESTRUCTIVE_OPERATIONS = &apos;destructive_operations&apos;,

  /** Data leakage to AI providers or logs */
  DATA_LEAKAGE = &apos;data_leakage&apos;,

  /** Resource exhaustion (API calls, disk, memory) */
  RESOURCE_EXHAUSTION = &apos;resource_exhaustion&apos;,

  /** Injection attacks through prompts or parameters */
  INJECTION_ATTACKS = &apos;injection_attacks&apos;,

  /** Privilege escalation */
  PRIVILEGE_ESCALATION = &apos;privilege_escalation&apos;
}

export interface Threat {
  category: ThreatCategory;
  description: string;
  severity: &apos;critical&apos; | &apos;high&apos; | &apos;medium&apos; | &apos;low&apos;;
  mitigation: string[];
  examples: string[];
}
</codeblock>
    <section><title>Common Threats</title></section>
    <codeblock outputclass="language-typescript">const threats: Threat[] = [
  {
    category: ThreatCategory.DESTRUCTIVE_OPERATIONS,
    description: &apos;AI executes commands that delete or corrupt data&apos;,
    severity: &apos;critical&apos;,
    mitigation: [
      &apos;Require approval for destructive operations&apos;,
      &apos;Implement sandboxing&apos;,
      &apos;Use read-only mode by default&apos;,
      &apos;Maintain audit trail&apos;
    ],
    examples: [
      &apos;DROP DATABASE production&apos;,
      &apos;rm -rf /&apos;,
      &apos;git push --force origin main&apos;,
      &apos;DELETE FROM users&apos;
    ]
  },
  {
    category: ThreatCategory.DATA_LEAKAGE,
    description: &apos;Sensitive data sent to AI providers or logged&apos;,
    severity: &apos;critical&apos;,
    mitigation: [
      &apos;Filter sensitive patterns before AI calls&apos;,
      &apos;Encrypt credentials at rest&apos;,
      &apos;Redact logs&apos;,
      &apos;Use private AI deployments for sensitive data&apos;
    ],
    examples: [
      &apos;API keys in code review&apos;,
      &apos;Database passwords in logs&apos;,
      &apos;Customer PII in prompts&apos;,
      &apos;Private tokens in conversation history&apos;
    ]
  },
  {
    category: ThreatCategory.UNAUTHORIZED_ACCESS,
    description: &apos;Access to files or systems outside allowed scope&apos;,
    severity: &apos;high&apos;,
    mitigation: [
      &apos;Implement path allowlist/blocklist&apos;,
      &apos;Use principle of least privilege&apos;,
      &apos;Sandbox file system access&apos;,
      &apos;Validate all paths&apos;
    ],
    examples: [
      &apos;Reading /etc/shadow&apos;,
      &apos;Accessing ~/.ssh/id_rsa&apos;,
      &apos;Reading .env files&apos;,
      &apos;Accessing parent directories&apos;
    ]
  },
  {
    category: ThreatCategory.RESOURCE_EXHAUSTION,
    description: &apos;Excessive API calls or resource usage&apos;,
    severity: &apos;medium&apos;,
    mitigation: [
      &apos;Implement rate limiting&apos;,
      &apos;Set budget caps&apos;,
      &apos;Monitor usage&apos;,
      &apos;Use request queuing&apos;
    ],
    examples: [
      &apos;Infinite loop calling AI&apos;,
      &apos;Processing entire codebase repeatedly&apos;,
      &apos;Exhausting API quotas&apos;,
      &apos;Memory leaks from large conversations&apos;
    ]
  }
];
</codeblock>
    <section><title>Security Architecture</title></section>
    <codeblock>┌─────────────────────────────────────────────────────────────┐
│                      User Input                              │
│           &quot;Delete old database backups&quot;                      │
└─────────────────────────────────────────────────────────────┘
                              ↓
┌─────────────────────────────────────────────────────────────┐
│                   Input Validation                           │
│  • Sanitize input                                            │
│  • Detect injection attempts                                 │
│  • Check against allowed patterns                            │
└─────────────────────────────────────────────────────────────┘
                              ↓
┌─────────────────────────────────────────────────────────────┐
│                  Privacy Filter                              │
│  • Redact secrets (API keys, passwords)                      │
│  • Remove PII                                                │
│  • Filter sensitive paths                                    │
└─────────────────────────────────────────────────────────────┘
                              ↓
┌─────────────────────────────────────────────────────────────┐
│                   AI Processing                              │
│  [Safe to send to AI provider]                              │
└─────────────────────────────────────────────────────────────┘
                              ↓
┌─────────────────────────────────────────────────────────────┐
│              Operation Classification                        │
│  Classify: READ | WRITE | DELETE | EXECUTE                  │
│  Risk level: SAFE | LOW | MEDIUM | HIGH | CRITICAL          │
└─────────────────────────────────────────────────────────────┘
                              ↓
┌─────────────────────────────────────────────────────────────┐
│                 Approval Gate                                │
│  • Auto-approve: SAFE, LOW risk operations                  │
│  • Require approval: MEDIUM+ risk                            │
│  • Require 2FA: CRITICAL risk                                │
└─────────────────────────────────────────────────────────────┘
                              ↓
┌─────────────────────────────────────────────────────────────┐
│                Sandboxed Execution                           │
│  • Path restrictions (allowlist/blocklist)                   │
│  • Resource limits (CPU, memory, time)                       │
│  • Network isolation (optional)                              │
│  • Capability restrictions                                   │
└─────────────────────────────────────────────────────────────┘
                              ↓
┌─────────────────────────────────────────────────────────────┐
│                   Audit Logging                              │
│  • Log all operations                                        │
│  • Redact sensitive data                                     │
│  • Include context and outcome                               │
│  • Enable forensics                                          │
└─────────────────────────────────────────────────────────────┘
</codeblock>
    <section><title>9.2 Sandboxed Execution</title></section>
    <p>Sandboxing restricts what operations the AI can perform, preventing unauthorized access and destructive actions.</p>
    <section><title>Sandbox Configuration</title></section>
    <codeblock outputclass="language-typescript">/**
 * Sandbox configuration for execution environment
 */
export interface SandboxConfig {
  /** Allowed file paths (glob patterns) */
  allowedPaths?: string[];

  /** Blocked file paths (glob patterns) - takes precedence */
  blockedPaths?: string[];

  /** Allowed commands to execute */
  allowedCommands?: string[];

  /** Maximum execution time per operation (ms) */
  maxExecutionTime?: number;

  /** Maximum memory usage (bytes) */
  maxMemory?: number;

  /** Maximum disk space usage (bytes) */
  maxDiskUsage?: number;

  /** Network access allowed */
  allowNetwork?: boolean;

  /** Environment variables to expose */
  allowedEnvVars?: string[];

  /** Working directory restriction */
  workingDirectory?: string;

  /** Read-only mode (no writes allowed) */
  readOnly?: boolean;
}

/**
 * Default secure sandbox configuration
 */
export const DEFAULT_SANDBOX_CONFIG: SandboxConfig = {
  allowedPaths: [
    &apos;src/**/*&apos;,
    &apos;test/**/*&apos;,
    &apos;lib/**/*&apos;,
    &apos;docs/**/*&apos;,
    &apos;package.json&apos;,
    &apos;tsconfig.json&apos;,
    &apos;README.md&apos;
  ],
  blockedPaths: [
    &apos;.env&apos;,
    &apos;.env.*&apos;,
    &apos;**/.env&apos;,
    &apos;**/*.key&apos;,
    &apos;**/*.pem&apos;,
    &apos;**/*.p12&apos;,
    &apos;**/id_rsa&apos;,
    &apos;**/id_dsa&apos;,
    &apos;**/*_key&apos;,
    &apos;**/credentials.*&apos;,
    &apos;**/secrets.*&apos;,
    &apos;.git/config&apos;,
    &apos;.ssh/**/*&apos;,
    &apos;/etc/**/*&apos;,
    &apos;/var/**/*&apos;,
    &apos;/usr/**/*&apos;,
    &apos;/home/*/.ssh/**/*&apos;,
    &apos;node_modules/**/*&apos;
  ],
  allowedCommands: [
    &apos;git status&apos;,
    &apos;git diff&apos;,
    &apos;git log&apos;,
    &apos;npm test&apos;,
    &apos;npm run test&apos;,
    &apos;yarn test&apos;,
    &apos;ls&apos;,
    &apos;cat&apos;,
    &apos;grep&apos;
  ],
  maxExecutionTime: 30000, // 30 seconds
  maxMemory: 512 * 1024 * 1024, // 512 MB
  maxDiskUsage: 100 * 1024 * 1024, // 100 MB
  allowNetwork: false,
  allowedEnvVars: [&apos;NODE_ENV&apos;, &apos;PATH&apos;],
  readOnly: false
};
</codeblock>
    <section><title>Sandbox Validator</title></section>
    <codeblock outputclass="language-typescript">import { minimatch } from &apos;minimatch&apos;;
import path from &apos;path&apos;;

/**
 * Validates operations against sandbox rules
 */
export class SandboxValidator {
  constructor(private config: SandboxConfig) {}

  /**
   * Check if file path is allowed
   */
  isPathAllowed(filePath: string): ValidationResult {
    const normalizedPath = path.normalize(filePath);

    // Check if path escapes working directory
    if (this.config.workingDirectory) {
      const resolved = path.resolve(this.config.workingDirectory, normalizedPath);
      if (!resolved.startsWith(this.config.workingDirectory)) {
        return {
          allowed: false,
          reason: &apos;Path escapes working directory&apos;,
          severity: &apos;critical&apos;
        };
      }
    }

    // Check blocked paths first (takes precedence)
    if (this.config.blockedPaths) {
      for (const pattern of this.config.blockedPaths) {
        if (minimatch(normalizedPath, pattern)) {
          return {
            allowed: false,
            reason: `Path matches blocked pattern: ${pattern}`,
            severity: &apos;high&apos;
          };
        }
      }
    }

    // Check allowed paths
    if (this.config.allowedPaths) {
      let matched = false;

      for (const pattern of this.config.allowedPaths) {
        if (minimatch(normalizedPath, pattern)) {
          matched = true;
          break;
        }
      }

      if (!matched) {
        return {
          allowed: false,
          reason: &apos;Path not in allowed list&apos;,
          severity: &apos;medium&apos;
        };
      }
    }

    return { allowed: true };
  }

  /**
   * Check if command is allowed
   */
  isCommandAllowed(command: string): ValidationResult {
    if (!this.config.allowedCommands) {
      // If no allowlist, reject all commands
      return {
        allowed: false,
        reason: &apos;Command execution not allowed&apos;,
        severity: &apos;high&apos;
      };
    }

    // Extract base command (first word)
    const baseCommand = command.trim().split(/\s+/)[0];

    // Check if command is in allowlist
    const allowed = this.config.allowedCommands.some(allowedCmd =&gt; {
      // Exact match
      if (command === allowedCmd) return true;

      // Prefix match (e.g., &quot;git&quot; allows &quot;git status&quot;)
      if (command.startsWith(allowedCmd + &apos; &apos;)) return true;

      // Base command match
      if (baseCommand === allowedCmd) return true;

      return false;
    });

    if (!allowed) {
      return {
        allowed: false,
        reason: `Command not in allowed list: ${baseCommand}`,
        severity: &apos;high&apos;
      };
    }

    // Check for dangerous patterns
    const dangerousPatterns = [
      /rm\s+-rf/,
      /dd\s+if=/,
      /mkfs/,
      /:\(\)\{.*\}:/,  // Fork bomb
      /&gt;\s*\/dev\/sd/,
      /curl.*\|\s*sh/,
      /wget.*\|\s*sh/,
      /sudo/,
      /chmod\s+777/
    ];

    for (const pattern of dangerousPatterns) {
      if (pattern.test(command)) {
        return {
          allowed: false,
          reason: &apos;Command contains dangerous pattern&apos;,
          severity: &apos;critical&apos;
        };
      }
    }

    return { allowed: true };
  }

  /**
   * Check if operation is allowed in read-only mode
   */
  isWriteAllowed(operation: &apos;create&apos; | &apos;update&apos; | &apos;delete&apos;): ValidationResult {
    if (this.config.readOnly) {
      return {
        allowed: false,
        reason: &apos;Sandbox is in read-only mode&apos;,
        severity: &apos;medium&apos;
      };
    }

    return { allowed: true };
  }

  /**
   * Check if network access is allowed
   */
  isNetworkAllowed(url: string): ValidationResult {
    if (!this.config.allowNetwork) {
      return {
        allowed: false,
        reason: &apos;Network access not allowed&apos;,
        severity: &apos;medium&apos;
      };
    }

    return { allowed: true };
  }
}

export interface ValidationResult {
  allowed: boolean;
  reason?: string;
  severity?: &apos;low&apos; | &apos;medium&apos; | &apos;high&apos; | &apos;critical&apos;;
}
</codeblock>
    <section><title>Sandboxed File System</title></section>
    <codeblock outputclass="language-typescript">import fs from &apos;fs/promises&apos;;

/**
 * Sandboxed file system operations
 */
export class SandboxedFileSystem {
  private validator: SandboxValidator;
  private logger: Logger;

  constructor(
    config: SandboxConfig,
    logger: Logger
  ) {
    this.validator = new SandboxValidator(config);
    this.logger = logger;
  }

  /**
   * Read file with sandbox validation
   */
  async readFile(filePath: string): Promise&lt;string&gt; {
    // Validate path
    const validation = this.validator.isPathAllowed(filePath);

    if (!validation.allowed) {
      this.logger.warn(&apos;Blocked file read:&apos;, {
        path: filePath,
        reason: validation.reason
      });

      throw new SecurityError(
        `Access denied: ${validation.reason}`,
        validation.severity || &apos;medium&apos;
      );
    }

    try {
      const content = await fs.readFile(filePath, &apos;utf-8&apos;);

      this.logger.debug(&apos;File read:&apos;, { path: filePath, size: content.length });

      return content;

    } catch (error) {
      this.logger.error(&apos;File read error:&apos;, { path: filePath, error });
      throw error;
    }
  }

  /**
   * Write file with sandbox validation
   */
  async writeFile(filePath: string, content: string): Promise&lt;void&gt; {
    // Validate write allowed
    const writeValidation = this.validator.isWriteAllowed(&apos;create&apos;);

    if (!writeValidation.allowed) {
      throw new SecurityError(
        `Write denied: ${writeValidation.reason}`,
        writeValidation.severity || &apos;medium&apos;
      );
    }

    // Validate path
    const pathValidation = this.validator.isPathAllowed(filePath);

    if (!pathValidation.allowed) {
      this.logger.warn(&apos;Blocked file write:&apos;, {
        path: filePath,
        reason: pathValidation.reason
      });

      throw new SecurityError(
        `Access denied: ${pathValidation.reason}`,
        pathValidation.severity || &apos;medium&apos;
      );
    }

    try {
      await fs.writeFile(filePath, content, &apos;utf-8&apos;);

      this.logger.info(&apos;File written:&apos;, {
        path: filePath,
        size: content.length
      });

    } catch (error) {
      this.logger.error(&apos;File write error:&apos;, { path: filePath, error });
      throw error;
    }
  }

  /**
   * Delete file with sandbox validation
   */
  async deleteFile(filePath: string): Promise&lt;void&gt; {
    // Validate write allowed
    const writeValidation = this.validator.isWriteAllowed(&apos;delete&apos;);

    if (!writeValidation.allowed) {
      throw new SecurityError(
        `Delete denied: ${writeValidation.reason}`,
        writeValidation.severity || &apos;medium&apos;
      );
    }

    // Validate path
    const pathValidation = this.validator.isPathAllowed(filePath);

    if (!pathValidation.allowed) {
      this.logger.warn(&apos;Blocked file delete:&apos;, {
        path: filePath,
        reason: pathValidation.reason
      });

      throw new SecurityError(
        `Access denied: ${pathValidation.reason}`,
        pathValidation.severity || &apos;medium&apos;
      );
    }

    try {
      await fs.unlink(filePath);

      this.logger.warn(&apos;File deleted:&apos;, { path: filePath });

    } catch (error) {
      this.logger.error(&apos;File delete error:&apos;, { path: filePath, error });
      throw error;
    }
  }

  /**
   * List directory with sandbox validation
   */
  async listDirectory(dirPath: string): Promise&lt;string[]&gt; {
    const validation = this.validator.isPathAllowed(dirPath);

    if (!validation.allowed) {
      throw new SecurityError(
        `Access denied: ${validation.reason}`,
        validation.severity || &apos;medium&apos;
      );
    }

    const entries = await fs.readdir(dirPath);

    // Filter entries by sandbox rules
    const allowed: string[] = [];

    for (const entry of entries) {
      const fullPath = path.join(dirPath, entry);
      const entryValidation = this.validator.isPathAllowed(fullPath);

      if (entryValidation.allowed) {
        allowed.push(entry);
      }
    }

    return allowed;
  }
}

export class SecurityError extends Error {
  constructor(
    message: string,
    public severity: &apos;low&apos; | &apos;medium&apos; | &apos;high&apos; | &apos;critical&apos;
  ) {
    super(message);
    this.name = &apos;SecurityError&apos;;
  }
}
</codeblock>
    <section><title>Sandboxed Command Execution</title></section>
    <codeblock outputclass="language-typescript">import { spawn } from &apos;child_process&apos;;

/**
 * Sandboxed command execution with resource limits
 */
export class SandboxedExecutor {
  private validator: SandboxValidator;
  private logger: Logger;

  constructor(
    private config: SandboxConfig,
    logger: Logger
  ) {
    this.validator = new SandboxValidator(config);
    this.logger = logger;
  }

  /**
   * Execute command with sandbox restrictions
   */
  async execute(command: string, cwd?: string): Promise&lt;ExecutionResult&gt; {
    // Validate command
    const validation = this.validator.isCommandAllowed(command);

    if (!validation.allowed) {
      this.logger.warn(&apos;Blocked command execution:&apos;, {
        command,
        reason: validation.reason
      });

      throw new SecurityError(
        `Command denied: ${validation.reason}`,
        validation.severity || &apos;high&apos;
      );
    }

    // Validate working directory
    if (cwd) {
      const cwdValidation = this.validator.isPathAllowed(cwd);

      if (!cwdValidation.allowed) {
        throw new SecurityError(
          `Working directory denied: ${cwdValidation.reason}`,
          cwdValidation.severity || &apos;medium&apos;
        );
      }
    }

    this.logger.info(&apos;Executing command:&apos;, { command, cwd });

    const startTime = Date.now();

    return new Promise((resolve, reject) =&gt; {
      // Parse command
      const args = command.split(/\s+/);
      const cmd = args[0];
      const cmdArgs = args.slice(1);

      // Spawn process
      const proc = spawn(cmd, cmdArgs, {
        cwd: cwd || this.config.workingDirectory,
        env: this.getFilteredEnv(),
        timeout: this.config.maxExecutionTime,
        maxBuffer: this.config.maxMemory
      });

      let stdout = &apos;&apos;;
      let stderr = &apos;&apos;;

      proc.stdout.on(&apos;data&apos;, data =&gt; {
        stdout += data.toString();
      });

      proc.stderr.on(&apos;data&apos;, data =&gt; {
        stderr += data.toString();
      });

      proc.on(&apos;error&apos;, error =&gt; {
        this.logger.error(&apos;Command execution error:&apos;, {
          command,
          error
        });

        reject(new SecurityError(
          `Execution failed: ${error.message}`,
          &apos;medium&apos;
        ));
      });

      proc.on(&apos;exit&apos;, (code, signal) =&gt; {
        const duration = Date.now() - startTime;

        this.logger.info(&apos;Command completed:&apos;, {
          command,
          code,
          signal,
          duration
        });

        resolve({
          success: code === 0,
          exitCode: code || 0,
          stdout,
          stderr,
          duration
        });
      });

      // Timeout handler
      if (this.config.maxExecutionTime) {
        setTimeout(() =&gt; {
          proc.kill(&apos;SIGTERM&apos;);

          setTimeout(() =&gt; {
            proc.kill(&apos;SIGKILL&apos;);
          }, 5000); // Force kill after 5s

        }, this.config.maxExecutionTime);
      }
    });
  }

  /**
   * Get filtered environment variables
   */
  private getFilteredEnv(): NodeJS.ProcessEnv {
    if (!this.config.allowedEnvVars) {
      return {};
    }

    const filtered: NodeJS.ProcessEnv = {};

    for (const key of this.config.allowedEnvVars) {
      if (process.env[key] !== undefined) {
        filtered[key] = process.env[key];
      }
    }

    return filtered;
  }
}

export interface ExecutionResult {
  success: boolean;
  exitCode: number;
  stdout: string;
  stderr: string;
  duration: number;
}
</codeblock>
    <section><title>9.3 Credential Management</title></section>
    <p>Secure storage and handling of API keys, passwords, and other credentials is critical.</p>
    <section><title>Credential Encryption</title></section>
    <codeblock outputclass="language-typescript">import crypto from &apos;crypto&apos;;

/**
 * Encrypts and decrypts credentials using AES-256-GCM
 */
export class CredentialEncryption {
  private algorithm = &apos;aes-256-gcm&apos;;
  private keyLength = 32; // 256 bits

  /**
   * Derive encryption key from password using PBKDF2
   */
  private async deriveKey(password: string, salt: Buffer): Promise&lt;Buffer&gt; {
    return new Promise((resolve, reject) =&gt; {
      crypto.pbkdf2(
        password,
        salt,
        100000, // iterations
        this.keyLength,
        &apos;sha256&apos;,
        (err, key) =&gt; {
          if (err) reject(err);
          else resolve(key);
        }
      );
    });
  }

  /**
   * Encrypt credential
   */
  async encrypt(
    credential: string,
    password: string
  ): Promise&lt;EncryptedCredential&gt; {
    // Generate random salt and IV
    const salt = crypto.randomBytes(16);
    const iv = crypto.randomBytes(16);

    // Derive key from password
    const key = await this.deriveKey(password, salt);

    // Create cipher
    const cipher = crypto.createCipheriv(this.algorithm, key, iv);

    // Encrypt
    let encrypted = cipher.update(credential, &apos;utf8&apos;, &apos;hex&apos;);
    encrypted += cipher.final(&apos;hex&apos;);

    // Get auth tag
    const authTag = cipher.getAuthTag();

    return {
      encrypted,
      salt: salt.toString(&apos;hex&apos;),
      iv: iv.toString(&apos;hex&apos;),
      authTag: authTag.toString(&apos;hex&apos;),
      algorithm: this.algorithm
    };
  }

  /**
   * Decrypt credential
   */
  async decrypt(
    encryptedCredential: EncryptedCredential,
    password: string
  ): Promise&lt;string&gt; {
    // Convert from hex
    const salt = Buffer.from(encryptedCredential.salt, &apos;hex&apos;);
    const iv = Buffer.from(encryptedCredential.iv, &apos;hex&apos;);
    const authTag = Buffer.from(encryptedCredential.authTag, &apos;hex&apos;);

    // Derive key
    const key = await this.deriveKey(password, salt);

    // Create decipher
    const decipher = crypto.createDecipheriv(this.algorithm, key, iv);
    decipher.setAuthTag(authTag);

    // Decrypt
    let decrypted = decipher.update(encryptedCredential.encrypted, &apos;hex&apos;, &apos;utf8&apos;);
    decrypted += decipher.final(&apos;utf8&apos;);

    return decrypted;
  }
}

export interface EncryptedCredential {
  encrypted: string;
  salt: string;
  iv: string;
  authTag: string;
  algorithm: string;
}
</codeblock>
    <section><title>Credential Store</title></section>
    <codeblock outputclass="language-typescript">import fs from &apos;fs/promises&apos;;
import os from &apos;os&apos;;

/**
 * Secure credential storage
 */
export class CredentialStore {
  private encryption: CredentialEncryption;
  private storePath: string;
  private masterPassword: string;
  private cache: Map&lt;string, string&gt; = new Map();

  constructor(
    storePath?: string,
    masterPassword?: string
  ) {
    this.encryption = new CredentialEncryption();
    this.storePath = storePath || path.join(os.homedir(), &apos;.ollama-code&apos;, &apos;credentials.enc&apos;);
    this.masterPassword = masterPassword || this.getMasterPassword();
  }

  /**
   * Get master password from environment or keychain
   */
  private getMasterPassword(): string {
    // Try environment variable first
    const envPassword = process.env.OLLAMA_CODE_MASTER_PASSWORD;
    if (envPassword) {
      return envPassword;
    }

    // TODO: Integrate with OS keychain
    // - macOS: Keychain Access
    // - Windows: Credential Manager
    // - Linux: Secret Service API

    throw new Error(
      &apos;Master password not set. Set OLLAMA_CODE_MASTER_PASSWORD environment variable.&apos;
    );
  }

  /**
   * Store credential
   */
  async set(key: string, value: string): Promise&lt;void&gt; {
    // Encrypt credential
    const encrypted = await this.encryption.encrypt(value, this.masterPassword);

    // Load existing store
    const store = await this.load();

    // Add encrypted credential
    store[key] = encrypted;

    // Save store
    await this.save(store);

    // Update cache
    this.cache.set(key, value);
  }

  /**
   * Get credential
   */
  async get(key: string): Promise&lt;string | null&gt; {
    // Check cache
    if (this.cache.has(key)) {
      return this.cache.get(key)!;
    }

    // Load store
    const store = await this.load();

    // Get encrypted credential
    const encrypted = store[key];

    if (!encrypted) {
      return null;
    }

    // Decrypt
    const decrypted = await this.encryption.decrypt(encrypted, this.masterPassword);

    // Cache
    this.cache.set(key, decrypted);

    return decrypted;
  }

  /**
   * Delete credential
   */
  async delete(key: string): Promise&lt;void&gt; {
    // Load store
    const store = await this.load();

    // Remove credential
    delete store[key];

    // Save
    await this.save(store);

    // Clear cache
    this.cache.delete(key);
  }

  /**
   * List credential keys (not values)
   */
  async list(): Promise&lt;string[]&gt; {
    const store = await this.load();
    return Object.keys(store);
  }

  /**
   * Load credential store from disk
   */
  private async load(): Promise&lt;Record&lt;string, EncryptedCredential&gt;&gt; {
    try {
      const data = await fs.readFile(this.storePath, &apos;utf-8&apos;);
      return JSON.parse(data);
    } catch (error) {
      // Store doesn&apos;t exist yet
      return {};
    }
  }

  /**
   * Save credential store to disk
   */
  private async save(store: Record&lt;string, EncryptedCredential&gt;): Promise&lt;void&gt; {
    // Ensure directory exists
    const dir = path.dirname(this.storePath);
    await fs.mkdir(dir, { recursive: true });

    // Write with restrictive permissions
    await fs.writeFile(
      this.storePath,
      JSON.stringify(store, null, 2),
      { mode: 0o600 } // Owner read/write only
    );
  }

  /**
   * Clear cache (for security)
   */
  clearCache(): void {
    this.cache.clear();
  }
}
</codeblock>
    <section><title>Credential Usage</title></section>
    <codeblock outputclass="language-typescript">/**
 * Example: Storing and using API keys
 */

// Initialize credential store
const credentialStore = new CredentialStore();

// Store API keys (one-time setup)
await credentialStore.set(&apos;anthropic_api_key&apos;, &apos;sk-ant-...&apos;);
await credentialStore.set(&apos;openai_api_key&apos;, &apos;sk-...&apos;);
await credentialStore.set(&apos;github_token&apos;, &apos;ghp_...&apos;);

// Retrieve API key when needed
const anthropicKey = await credentialStore.get(&apos;anthropic_api_key&apos;);

// Use with AI provider
const provider = new AnthropicProvider({
  apiKey: anthropicKey!,
  model: &apos;claude-3-5-sonnet-20241022&apos;
});

// Delete credential
await credentialStore.delete(&apos;old_api_key&apos;);

// List all stored credentials
const keys = await credentialStore.list();
console.log(&apos;Stored credentials:&apos;, keys);
// Output: [&apos;anthropic_api_key&apos;, &apos;openai_api_key&apos;, &apos;github_token&apos;]
</codeblock>
    <section><title>9.4 Input Validation and Sanitization</title></section>
    <p>Validate and sanitize all user input to prevent injection attacks and data leakage.</p>
    <section><title>Input Validator</title></section>
    <codeblock outputclass="language-typescript">/**
 * Validates and sanitizes user input
 */
export class InputValidator {
  private logger: Logger;

  // Patterns for sensitive data
  private sensitivePatterns = [
    // API keys
    /sk-[a-zA-Z0-9]{20,}/g,
    /sk-ant-[a-zA-Z0-9-_]{20,}/g,
    /ghp_[a-zA-Z0-9]{36}/g,
    /gho_[a-zA-Z0-9]{36}/g,

    // AWS credentials
    /AKIA[0-9A-Z]{16}/g,
    /aws_secret_access_key[&quot;\s:=]+[a-zA-Z0-9/+=]{40}/gi,

    // Private keys
    /-----BEGIN (RSA |DSA |EC )?PRIVATE KEY-----/g,

    // Passwords
    /password[&quot;\s:=]+[^\s&quot;]{8,}/gi,
    /passwd[&quot;\s:=]+[^\s&quot;]{8,}/gi,

    // Tokens
    /token[&quot;\s:=]+[a-zA-Z0-9_-]{20,}/gi,
    /bearer\s+[a-zA-Z0-9_-]{20,}/gi,

    // Database connection strings
    /mongodb(\+srv)?:\/\/[^:]+:[^@]+@/gi,
    /postgres:\/\/[^:]+:[^@]+@/gi,
    /mysql:\/\/[^:]+:[^@]+@/gi,

    // Email addresses (PII)
    /[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}/g,

    // Credit card numbers
    /\b\d{4}[\s-]?\d{4}[\s-]?\d{4}[\s-]?\d{4}\b/g,

    // SSN
    /\b\d{3}-\d{2}-\d{4}\b/g
  ];

  // Patterns for injection attempts
  private injectionPatterns = [
    // Command injection
    /;\s*(rm|dd|mkfs|kill|shutdown)/i,
    /\|\s*(curl|wget).*\|\s*sh/i,
    /`[^`]*`/g, // Backticks
    /\$\([^)]*\)/g, // Command substitution

    // SQL injection
    /(union|select|insert|update|delete|drop|create|alter).*from/gi,
    /(&apos;|&quot;)\s*(or|and)\s*(&apos;|&quot;)/gi,

    // Path traversal
    /\.\.[\/\\]/g,
    /(\.\.\/){2,}/g,

    // XSS
    /&lt;script[^&gt;]*&gt;.*?&lt;\/script&gt;/gi,
    /javascript:/gi,
    /on\w+\s*=/gi // Event handlers
  ];

  constructor(logger: Logger) {
    this.logger = logger;
  }

  /**
   * Validate input and detect issues
   */
  validate(input: string): ValidationResult {
    const issues: ValidationIssue[] = [];

    // Check for sensitive data
    for (const pattern of this.sensitivePatterns) {
      if (pattern.test(input)) {
        issues.push({
          type: &apos;sensitive_data&apos;,
          severity: &apos;critical&apos;,
          message: &apos;Input contains sensitive data (API key, password, etc.)&apos;,
          pattern: pattern.toString()
        });
      }
    }

    // Check for injection attempts
    for (const pattern of this.injectionPatterns) {
      if (pattern.test(input)) {
        issues.push({
          type: &apos;injection_attempt&apos;,
          severity: &apos;high&apos;,
          message: &apos;Input contains potential injection pattern&apos;,
          pattern: pattern.toString()
        });
      }
    }

    // Check length
    if (input.length &gt; 50000) {
      issues.push({
        type: &apos;excessive_length&apos;,
        severity: &apos;medium&apos;,
        message: &apos;Input exceeds maximum length&apos;,
        pattern: &apos;length &gt; 50000&apos;
      });
    }

    const valid = issues.length === 0;

    if (!valid) {
      this.logger.warn(&apos;Input validation failed:&apos;, {
        issues,
        inputLength: input.length
      });
    }

    return {
      valid,
      issues
    };
  }

  /**
   * Sanitize input by redacting sensitive data
   */
  sanitize(input: string): string {
    let sanitized = input;

    // Redact sensitive patterns
    for (const pattern of this.sensitivePatterns) {
      sanitized = sanitized.replace(pattern, &apos;[REDACTED]&apos;);
    }

    return sanitized;
  }

  /**
   * Check if input is safe to send to AI
   */
  isSafeForAI(input: string): boolean {
    const validation = this.validate(input);

    // Block if contains sensitive data
    const hasSensitiveData = validation.issues.some(
      issue =&gt; issue.type === &apos;sensitive_data&apos;
    );

    return !hasSensitiveData;
  }

  /**
   * Check if input is safe to execute
   */
  isSafeForExecution(input: string): boolean {
    const validation = this.validate(input);

    // Block if contains injection attempts
    const hasInjection = validation.issues.some(
      issue =&gt; issue.type === &apos;injection_attempt&apos;
    );

    return !hasInjection;
  }
}

export interface ValidationIssue {
  type: &apos;sensitive_data&apos; | &apos;injection_attempt&apos; | &apos;excessive_length&apos;;
  severity: &apos;low&apos; | &apos;medium&apos; | &apos;high&apos; | &apos;critical&apos;;
  message: string;
  pattern: string;
}
</codeblock>
    <section><title>Privacy Filter</title></section>
    <codeblock outputclass="language-typescript">/**
 * Filters sensitive data before sending to AI
 */
export class PrivacyFilter {
  private validator: InputValidator;
  private logger: Logger;

  constructor(logger: Logger) {
    this.validator = new InputValidator(logger);
    this.logger = logger;
  }

  /**
   * Filter input before sending to AI
   */
  async filterForAI(input: string): Promise&lt;FilterResult&gt; {
    // Sanitize sensitive data
    const sanitized = this.validator.sanitize(input);

    // Check if safe
    const safe = this.validator.isSafeForAI(input);

    if (!safe) {
      this.logger.warn(&apos;Input filtered for AI:&apos;, {
        originalLength: input.length,
        sanitizedLength: sanitized.length
      });
    }

    return {
      filtered: sanitized,
      hadSensitiveData: !safe,
      redactions: this.countRedactions(input, sanitized)
    };
  }

  /**
   * Filter file content before sending to AI
   */
  async filterFileContent(
    filePath: string,
    content: string
  ): Promise&lt;FilterResult&gt; {
    // Check if file should be entirely blocked
    if (this.isBlockedFile(filePath)) {
      this.logger.warn(&apos;Blocked file from AI:&apos;, { path: filePath });

      return {
        filtered: `[File ${filePath} contains sensitive data and was not sent to AI]`,
        hadSensitiveData: true,
        redactions: 1
      };
    }

    // Filter content
    return this.filterForAI(content);
  }

  /**
   * Check if file is sensitive and should be blocked
   */
  private isBlockedFile(filePath: string): boolean {
    const blockedPatterns = [
      /\.env$/,
      /\.env\./,
      /credentials/i,
      /secrets/i,
      /\.key$/,
      /\.pem$/,
      /id_rsa$/,
      /id_dsa$/
    ];

    return blockedPatterns.some(pattern =&gt; pattern.test(filePath));
  }

  /**
   * Count number of redactions made
   */
  private countRedactions(original: string, filtered: string): number {
    const redactionPattern = /\[REDACTED\]/g;
    const matches = filtered.match(redactionPattern);
    return matches ? matches.length : 0;
  }
}

export interface FilterResult {
  filtered: string;
  hadSensitiveData: boolean;
  redactions: number;
}
</codeblock>
    <section><title>9.5 Rate Limiting and Quotas</title></section>
    <p>Prevent resource exhaustion by limiting API calls and resource usage.</p>
    <section><title>Rate Limiter</title></section>
    <codeblock outputclass="language-typescript">/**
 * Token bucket rate limiter
 */
export class RateLimiter {
  private tokens: number;
  private lastRefill: number;

  constructor(
    private maxTokens: number,
    private refillRate: number, // tokens per second
    private logger: Logger
  ) {
    this.tokens = maxTokens;
    this.lastRefill = Date.now();
  }

  /**
   * Try to consume tokens
   * @returns true if tokens available, false if rate limited
   */
  async tryConsume(tokensNeeded: number = 1): Promise&lt;boolean&gt; {
    // Refill tokens based on time elapsed
    this.refill();

    if (this.tokens &gt;= tokensNeeded) {
      this.tokens -= tokensNeeded;
      return true;
    }

    this.logger.warn(&apos;Rate limit exceeded:&apos;, {
      available: this.tokens,
      needed: tokensNeeded
    });

    return false;
  }

  /**
   * Wait until tokens are available
   */
  async consume(tokensNeeded: number = 1): Promise&lt;void&gt; {
    while (true) {
      if (await this.tryConsume(tokensNeeded)) {
        return;
      }

      // Calculate wait time
      const tokensToWait = tokensNeeded - this.tokens;
      const waitMs = (tokensToWait / this.refillRate) * 1000;

      // Wait
      await new Promise(resolve =&gt; setTimeout(resolve, waitMs));
    }
  }

  /**
   * Refill tokens based on elapsed time
   */
  private refill(): void {
    const now = Date.now();
    const elapsedMs = now - this.lastRefill;
    const elapsedSeconds = elapsedMs / 1000;

    const tokensToAdd = elapsedSeconds * this.refillRate;

    this.tokens = Math.min(this.maxTokens, this.tokens + tokensToAdd);
    this.lastRefill = now;
  }

  /**
   * Get current token count
   */
  getAvailableTokens(): number {
    this.refill();
    return this.tokens;
  }
}
</codeblock>
    <section><title>Budget Manager</title></section>
    <codeblock outputclass="language-typescript">/**
 * Manages budget limits for AI API calls
 */
export class BudgetManager {
  private usage: UsageTracker;
  private logger: Logger;

  constructor(
    private limits: BudgetLimits,
    logger: Logger
  ) {
    this.usage = new UsageTracker();
    this.logger = logger;
  }

  /**
   * Check if request is within budget
   */
  async checkBudget(estimatedCost: number): Promise&lt;BudgetCheckResult&gt; {
    const current = this.usage.getCurrentUsage();

    // Check hourly limit
    if (this.limits.hourlyLimit) {
      const hourlyUsage = this.usage.getUsageInWindow(3600000); // 1 hour

      if (hourlyUsage.cost + estimatedCost &gt; this.limits.hourlyLimit) {
        return {
          allowed: false,
          reason: &apos;Hourly budget limit exceeded&apos;,
          current: hourlyUsage.cost,
          limit: this.limits.hourlyLimit
        };
      }
    }

    // Check daily limit
    if (this.limits.dailyLimit) {
      const dailyUsage = this.usage.getUsageInWindow(86400000); // 24 hours

      if (dailyUsage.cost + estimatedCost &gt; this.limits.dailyLimit) {
        return {
          allowed: false,
          reason: &apos;Daily budget limit exceeded&apos;,
          current: dailyUsage.cost,
          limit: this.limits.dailyLimit
        };
      }
    }

    // Check monthly limit
    if (this.limits.monthlyLimit) {
      const monthlyUsage = this.usage.getUsageInWindow(2592000000); // 30 days

      if (monthlyUsage.cost + estimatedCost &gt; this.limits.monthlyLimit) {
        return {
          allowed: false,
          reason: &apos;Monthly budget limit exceeded&apos;,
          current: monthlyUsage.cost,
          limit: this.limits.monthlyLimit
        };
      }
    }

    return { allowed: true };
  }

  /**
   * Record usage
   */
  async recordUsage(cost: number, tokens: number, provider: string): Promise&lt;void&gt; {
    this.usage.record({
      timestamp: Date.now(),
      cost,
      tokens,
      provider
    });

    this.logger.info(&apos;API usage recorded:&apos;, { cost, tokens, provider });
  }

  /**
   * Get current usage stats
   */
  getUsageStats(): UsageStats {
    return {
      hourly: this.usage.getUsageInWindow(3600000),
      daily: this.usage.getUsageInWindow(86400000),
      monthly: this.usage.getUsageInWindow(2592000000),
      total: this.usage.getCurrentUsage()
    };
  }
}

export interface BudgetLimits {
  hourlyLimit?: number;
  dailyLimit?: number;
  monthlyLimit?: number;
}

export interface BudgetCheckResult {
  allowed: boolean;
  reason?: string;
  current?: number;
  limit?: number;
}

export interface UsageStats {
  hourly: { cost: number; tokens: number };
  daily: { cost: number; tokens: number };
  monthly: { cost: number; tokens: number };
  total: { cost: number; tokens: number };
}

/**
 * Tracks API usage over time
 */
class UsageTracker {
  private records: UsageRecord[] = [];

  record(record: UsageRecord): void {
    this.records.push(record);

    // Clean old records (older than 30 days)
    const cutoff = Date.now() - 2592000000;
    this.records = this.records.filter(r =&gt; r.timestamp &gt; cutoff);
  }

  getUsageInWindow(windowMs: number): { cost: number; tokens: number } {
    const cutoff = Date.now() - windowMs;

    const filtered = this.records.filter(r =&gt; r.timestamp &gt; cutoff);

    return {
      cost: filtered.reduce((sum, r) =&gt; sum + r.cost, 0),
      tokens: filtered.reduce((sum, r) =&gt; sum + r.tokens, 0)
    };
  }

  getCurrentUsage(): { cost: number; tokens: number } {
    return {
      cost: this.records.reduce((sum, r) =&gt; sum + r.cost, 0),
      tokens: this.records.reduce((sum, r) =&gt; sum + r.tokens, 0)
    };
  }
}

interface UsageRecord {
  timestamp: number;
  cost: number;
  tokens: number;
  provider: string;
}
</codeblock>
    <section><title>9.6 Privacy-Preserving AI Interactions</title></section>
    <p>Minimize data exposure to AI providers while maintaining functionality.</p>
    <section><title>Local-First Strategy</title></section>
    <codeblock outputclass="language-typescript">/**
 * Privacy-preserving AI interaction strategy
 */
export class PrivacyPreservingAI {
  private privacyFilter: PrivacyFilter;
  private localProvider: AIProvider; // Ollama
  private cloudProvider: AIProvider; // Anthropic/OpenAI
  private logger: Logger;

  constructor(
    localProvider: AIProvider,
    cloudProvider: AIProvider,
    logger: Logger
  ) {
    this.privacyFilter = new PrivacyFilter(logger);
    this.localProvider = localProvider;
    this.cloudProvider = cloudProvider;
    this.logger = logger;
  }

  /**
   * Route request based on sensitivity
   */
  async complete(request: CompletionRequest): Promise&lt;CompletionResponse&gt; {
    // Analyze sensitivity
    const sensitivity = this.analyzeSensitivity(request);

    this.logger.info(&apos;Privacy routing:&apos;, {
      sensitivity: sensitivity.level,
      reasons: sensitivity.reasons
    });

    // Route based on sensitivity
    if (sensitivity.level === &apos;high&apos; || sensitivity.level === &apos;critical&apos;) {
      // Use local provider for sensitive data
      return this.localProvider.complete(request);

    } else {
      // Filter and use cloud provider for non-sensitive data
      const filtered = await this.filterRequest(request);
      return this.cloudProvider.complete(filtered);
    }
  }

  /**
   * Analyze sensitivity of request
   */
  private analyzeSensitivity(request: CompletionRequest): SensitivityAnalysis {
    const reasons: string[] = [];
    let level: SensitivityLevel = &apos;low&apos;;

    // Check each message
    for (const message of request.messages) {
      const validation = new InputValidator(this.logger).validate(message.content);

      for (const issue of validation.issues) {
        if (issue.type === &apos;sensitive_data&apos;) {
          level = &apos;critical&apos;;
          reasons.push(`Message contains ${issue.message}`);
        }
      }
    }

    // Check for code files
    const hasCodeFiles = request.messages.some(m =&gt;
      m.content.includes(&apos;```&apos;) || m.content.length &gt; 5000
    );

    if (hasCodeFiles) {
      if (level === &apos;low&apos;) level = &apos;medium&apos;;
      reasons.push(&apos;Request contains code files&apos;);
    }

    return { level, reasons };
  }

  /**
   * Filter request before sending to cloud
   */
  private async filterRequest(
    request: CompletionRequest
  ): Promise&lt;CompletionRequest&gt; {
    const filteredMessages = await Promise.all(
      request.messages.map(async msg =&gt; {
        const result = await this.privacyFilter.filterForAI(msg.content);

        return {
          ...msg,
          content: result.filtered
        };
      })
    );

    return {
      ...request,
      messages: filteredMessages
    };
  }
}

type SensitivityLevel = &apos;low&apos; | &apos;medium&apos; | &apos;high&apos; | &apos;critical&apos;;

interface SensitivityAnalysis {
  level: SensitivityLevel;
  reasons: string[];
}
</codeblock>
    <section><title>Anonymization</title></section>
    <codeblock outputclass="language-typescript">/**
 * Anonymizes code and data before sending to AI
 */
export class CodeAnonymizer {
  private identifierMap: Map&lt;string, string&gt; = new Map();
  private counter = 0;

  /**
   * Anonymize code by replacing identifiers
   */
  anonymize(code: string, language: string): AnonymizedCode {
    // Simple anonymization (production would use AST parsing)
    let anonymized = code;

    // Replace function names
    anonymized = anonymized.replace(
      /function\s+([a-zA-Z_][a-zA-Z0-9_]*)/g,
      (match, name) =&gt; {
        const anon = this.getAnonymousName(name);
        return `function ${anon}`;
      }
    );

    // Replace variable names
    anonymized = anonymized.replace(
      /(?:const|let|var)\s+([a-zA-Z_][a-zA-Z0-9_]*)/g,
      (match, name) =&gt; {
        const anon = this.getAnonymousName(name);
        return match.replace(name, anon);
      }
    );

    // Replace class names
    anonymized = anonymized.replace(
      /class\s+([a-zA-Z_][a-zA-Z0-9_]*)/g,
      (match, name) =&gt; {
        const anon = this.getAnonymousName(name);
        return `class ${anon}`;
      }
    );

    return {
      anonymized,
      identifierMap: new Map(this.identifierMap)
    };
  }

  /**
   * Deanonymize response from AI
   */
  deanonymize(code: string): string {
    let deanonymized = code;

    // Reverse identifier mapping
    for (const [original, anon] of this.identifierMap) {
      deanonymized = deanonymized.replace(
        new RegExp(`\\b${anon}\\b`, &apos;g&apos;),
        original
      );
    }

    return deanonymized;
  }

  /**
   * Get or create anonymous name
   */
  private getAnonymousName(original: string): string {
    if (this.identifierMap.has(original)) {
      return this.identifierMap.get(original)!;
    }

    const anon = `var_${this.counter++}`;
    this.identifierMap.set(original, anon);

    return anon;
  }

  /**
   * Clear mapping
   */
  reset(): void {
    this.identifierMap.clear();
    this.counter = 0;
  }
}

interface AnonymizedCode {
  anonymized: string;
  identifierMap: Map&lt;string, string&gt;;
}
</codeblock>
    <section><title>9.7 Audit Logging and Compliance</title></section>
    <p>Comprehensive audit logging enables forensics and compliance.</p>
    <section><title>Audit Logger</title></section>
    <codeblock outputclass="language-typescript">/**
 * Audit logger for security-relevant events
 */
export class AuditLogger {
  private logger: Logger;
  private storage: AuditStorage;

  constructor(logger: Logger, storage: AuditStorage) {
    this.logger = logger;
    this.storage = storage;
  }

  /**
   * Log security event
   */
  async logSecurityEvent(event: SecurityEvent): Promise&lt;void&gt; {
    // Add metadata
    const auditEvent: AuditEvent = {
      ...event,
      timestamp: new Date(),
      id: this.generateEventId()
    };

    // Redact sensitive data
    const redacted = this.redactEvent(auditEvent);

    // Write to logger
    this.logger.info(&apos;Security event:&apos;, redacted);

    // Store for audit
    await this.storage.store(redacted);
  }

  /**
   * Log file access
   */
  async logFileAccess(
    operation: &apos;read&apos; | &apos;write&apos; | &apos;delete&apos;,
    filePath: string,
    success: boolean,
    user?: string
  ): Promise&lt;void&gt; {
    await this.logSecurityEvent({
      type: &apos;file_access&apos;,
      operation,
      resource: filePath,
      success,
      user,
      metadata: {}
    });
  }

  /**
   * Log command execution
   */
  async logCommandExecution(
    command: string,
    success: boolean,
    exitCode?: number,
    user?: string
  ): Promise&lt;void&gt; {
    await this.logSecurityEvent({
      type: &apos;command_execution&apos;,
      operation: &apos;execute&apos;,
      resource: command,
      success,
      user,
      metadata: { exitCode }
    });
  }

  /**
   * Log credential access
   */
  async logCredentialAccess(
    operation: &apos;get&apos; | &apos;set&apos; | &apos;delete&apos;,
    key: string,
    success: boolean,
    user?: string
  ): Promise&lt;void&gt; {
    await this.logSecurityEvent({
      type: &apos;credential_access&apos;,
      operation,
      resource: key,
      success,
      user,
      metadata: {}
    });
  }

  /**
   * Log security violation
   */
  async logViolation(
    violationType: string,
    resource: string,
    reason: string,
    severity: &apos;low&apos; | &apos;medium&apos; | &apos;high&apos; | &apos;critical&apos;,
    user?: string
  ): Promise&lt;void&gt; {
    await this.logSecurityEvent({
      type: &apos;security_violation&apos;,
      operation: violationType,
      resource,
      success: false,
      user,
      metadata: { reason, severity }
    });
  }

  /**
   * Redact sensitive data from event
   */
  private redactEvent(event: AuditEvent): AuditEvent {
    const redacted = { ...event };

    // Redact resource if it contains sensitive data
    if (redacted.resource) {
      const validator = new InputValidator(this.logger);
      redacted.resource = validator.sanitize(redacted.resource);
    }

    return redacted;
  }

  /**
   * Generate unique event ID
   */
  private generateEventId(): string {
    return `${Date.now()}-${Math.random().toString(36).substring(7)}`;
  }
}

export interface SecurityEvent {
  type: string;
  operation: string;
  resource: string;
  success: boolean;
  user?: string;
  metadata: Record&lt;string, any&gt;;
}

export interface AuditEvent extends SecurityEvent {
  id: string;
  timestamp: Date;
}
</codeblock>
    <section><title>Audit Storage</title></section>
    <codeblock outputclass="language-typescript">import fs from &apos;fs/promises&apos;;

/**
 * Stores audit events for compliance
 */
export class AuditStorage {
  private logPath: string;
  private rotateSize: number; // bytes
  private maxFiles: number;

  constructor(
    logPath: string,
    rotateSize: number = 10 * 1024 * 1024, // 10 MB
    maxFiles: number = 10
  ) {
    this.logPath = logPath;
    this.rotateSize = rotateSize;
    this.maxFiles = maxFiles;
  }

  /**
   * Store audit event
   */
  async store(event: AuditEvent): Promise&lt;void&gt; {
    // Ensure directory exists
    const dir = path.dirname(this.logPath);
    await fs.mkdir(dir, { recursive: true });

    // Append to log file
    const line = JSON.stringify(event) + &apos;\n&apos;;
    await fs.appendFile(this.logPath, line);

    // Check if rotation needed
    await this.rotateIfNeeded();
  }

  /**
   * Query audit events
   */
  async query(filter: AuditFilter): Promise&lt;AuditEvent[]&gt; {
    const events: AuditEvent[] = [];

    // Read all log files
    const files = await this.getLogFiles();

    for (const file of files) {
      const content = await fs.readFile(file, &apos;utf-8&apos;);
      const lines = content.split(&apos;\n&apos;).filter(line =&gt; line.trim());

      for (const line of lines) {
        try {
          const event = JSON.parse(line);

          if (this.matchesFilter(event, filter)) {
            events.push(event);
          }
        } catch (error) {
          // Skip invalid lines
        }
      }
    }

    return events;
  }

  /**
   * Rotate log file if needed
   */
  private async rotateIfNeeded(): Promise&lt;void&gt; {
    try {
      const stats = await fs.stat(this.logPath);

      if (stats.size &gt;= this.rotateSize) {
        await this.rotate();
      }
    } catch (error) {
      // File doesn&apos;t exist yet
    }
  }

  /**
   * Rotate log files
   */
  private async rotate(): Promise&lt;void&gt; {
    // Move existing files
    for (let i = this.maxFiles - 1; i &gt; 0; i--) {
      const oldPath = `${this.logPath}.${i}`;
      const newPath = `${this.logPath}.${i + 1}`;

      try {
        await fs.rename(oldPath, newPath);
      } catch (error) {
        // File doesn&apos;t exist
      }
    }

    // Move current file to .1
    await fs.rename(this.logPath, `${this.logPath}.1`);

    // Delete oldest file if needed
    const oldestPath = `${this.logPath}.${this.maxFiles + 1}`;
    try {
      await fs.unlink(oldestPath);
    } catch (error) {
      // File doesn&apos;t exist
    }
  }

  /**
   * Get all log files
   */
  private async getLogFiles(): Promise&lt;string[]&gt; {
    const files = [this.logPath];

    for (let i = 1; i &lt;= this.maxFiles; i++) {
      const path = `${this.logPath}.${i}`;

      try {
        await fs.access(path);
        files.push(path);
      } catch (error) {
        // File doesn&apos;t exist
        break;
      }
    }

    return files;
  }

  /**
   * Check if event matches filter
   */
  private matchesFilter(event: AuditEvent, filter: AuditFilter): boolean {
    if (filter.type &amp;&amp; event.type !== filter.type) {
      return false;
    }

    if (filter.operation &amp;&amp; event.operation !== filter.operation) {
      return false;
    }

    if (filter.user &amp;&amp; event.user !== filter.user) {
      return false;
    }

    if (filter.startTime &amp;&amp; event.timestamp &lt; filter.startTime) {
      return false;
    }

    if (filter.endTime &amp;&amp; event.timestamp &gt; filter.endTime) {
      return false;
    }

    return true;
  }
}

export interface AuditFilter {
  type?: string;
  operation?: string;
  user?: string;
  startTime?: Date;
  endTime?: Date;
}
</codeblock>
    <section><title>9.8 Security Best Practices</title></section>
    <section><title>Security Checklist</title></section>
    <codeblock outputclass="language-typescript">/**
 * Security best practices checklist
 */
export const SECURITY_CHECKLIST = {
  authentication: [
    &apos;Use encrypted credential storage (AES-256-GCM)&apos;,
    &apos;Never store credentials in plaintext&apos;,
    &apos;Use OS keychain when available&apos;,
    &apos;Rotate credentials regularly&apos;,
    &apos;Use principle of least privilege&apos;
  ],

  authorization: [
    &apos;Implement sandbox for file access&apos;,
    &apos;Require approval for destructive operations&apos;,
    &apos;Use allowlists for paths and commands&apos;,
    &apos;Validate all user input&apos;,
    &apos;Implement read-only mode&apos;
  ],

  dataProtection: [
    &apos;Filter sensitive data before sending to AI&apos;,
    &apos;Use local AI for sensitive code&apos;,
    &apos;Redact secrets in logs&apos;,
    &apos;Anonymize code when possible&apos;,
    &apos;Encrypt data at rest and in transit&apos;
  ],

  rateLimiting: [
    &apos;Implement rate limiting for API calls&apos;,
    &apos;Set budget caps (hourly, daily, monthly)&apos;,
    &apos;Monitor usage patterns&apos;,
    &apos;Alert on unusual activity&apos;,
    &apos;Implement request queuing&apos;
  ],

  auditLogging: [
    &apos;Log all security-relevant events&apos;,
    &apos;Include context (user, timestamp, resource)&apos;,
    &apos;Redact sensitive data in logs&apos;,
    &apos;Rotate logs regularly&apos;,
    &apos;Enable forensic analysis&apos;
  ],

  inputValidation: [
    &apos;Validate all user input&apos;,
    &apos;Sanitize before processing&apos;,
    &apos;Detect injection attempts&apos;,
    &apos;Limit input length&apos;,
    &apos;Use type checking&apos;
  ],

  errorHandling: [
    &apos;Never expose sensitive data in errors&apos;,
    &apos;Log errors securely&apos;,
    &apos;Fail securely (deny by default)&apos;,
    &apos;Handle edge cases&apos;,
    &apos;Provide user-friendly messages&apos;
  ],

  deployment: [
    &apos;Run with least privilege&apos;,
    &apos;Use environment variables for config&apos;,
    &apos;Enable security headers&apos;,
    &apos;Keep dependencies updated&apos;,
    &apos;Regular security audits&apos;
  ]
};
</codeblock>
    <section><title>Secure Configuration</title></section>
    <codeblock outputclass="language-typescript">/**
 * Secure default configuration
 */
export class SecureConfiguration {
  /**
   * Get production-ready security configuration
   */
  static getProductionConfig(): SecurityConfig {
    return {
      // Sandbox configuration
      sandbox: {
        ...DEFAULT_SANDBOX_CONFIG,
        readOnly: false,
        allowNetwork: false,
        maxExecutionTime: 30000
      },

      // Credential configuration
      credentials: {
        storePath: path.join(os.homedir(), &apos;.ollama-code&apos;, &apos;credentials.enc&apos;),
        encryptionAlgorithm: &apos;aes-256-gcm&apos;,
        keyDerivationIterations: 100000
      },

      // Rate limiting
      rateLimits: {
        requestsPerMinute: 60,
        requestsPerHour: 1000,
        requestsPerDay: 10000
      },

      // Budget limits
      budget: {
        hourlyLimit: 1.00, // $1/hour
        dailyLimit: 10.00, // $10/day
        monthlyLimit: 100.00 // $100/month
      },

      // Privacy
      privacy: {
        filterSensitiveData: true,
        useLocalForSensitive: true,
        anonymizeCode: false, // Optional
        redactLogs: true
      },

      // Audit logging
      audit: {
        enabled: true,
        logPath: path.join(os.homedir(), &apos;.ollama-code&apos;, &apos;audit.log&apos;),
        rotateSize: 10 * 1024 * 1024, // 10 MB
        maxFiles: 10
      },

      // Approval requirements
      approval: {
        requireForWrite: true,
        requireForDelete: true,
        requireForExecute: true,
        requireFor2FA: [&apos;delete&apos;, &apos;execute_dangerous&apos;]
      }
    };
  }

  /**
   * Get development configuration (more permissive)
   */
  static getDevelopmentConfig(): SecurityConfig {
    const prod = this.getProductionConfig();

    return {
      ...prod,
      sandbox: {
        ...prod.sandbox,
        allowNetwork: true,
        maxExecutionTime: 60000
      },
      approval: {
        ...prod.approval,
        requireForWrite: false,
        requireForExecute: false
      }
    };
  }
}

export interface SecurityConfig {
  sandbox: SandboxConfig;
  credentials: CredentialConfig;
  rateLimits: RateLimitConfig;
  budget: BudgetLimits;
  privacy: PrivacyConfig;
  audit: AuditConfig;
  approval: ApprovalConfig;
}

interface CredentialConfig {
  storePath: string;
  encryptionAlgorithm: string;
  keyDerivationIterations: number;
}

interface RateLimitConfig {
  requestsPerMinute: number;
  requestsPerHour: number;
  requestsPerDay: number;
}

interface PrivacyConfig {
  filterSensitiveData: boolean;
  useLocalForSensitive: boolean;
  anonymizeCode: boolean;
  redactLogs: boolean;
}

interface AuditConfig {
  enabled: boolean;
  logPath: string;
  rotateSize: number;
  maxFiles: number;
}

interface ApprovalConfig {
  requireForWrite: boolean;
  requireForDelete: boolean;
  requireForExecute: boolean;
  requireFor2FA: string[];
}
</codeblock>
    <section><title>Exercises</title></section>
    <section><title>Exercise 1: Implement Container-Based Sandboxing</title></section>
    <p><b>Goal:</b> Enhance sandboxing by using Docker containers for complete isolation.</p>
    <p><b>Requirements:</b>
1. Create <codeph>DockerSandbox</codeph> class that executes commands in containers
2. Mount only allowed directories
3. Limit CPU, memory, and network
4. Collect output and cleanup containers
5. Handle errors and timeouts</p>
    <p><b>Starter Code:</b></p>
    <codeblock outputclass="language-typescript">export class DockerSandbox {
  async execute(command: string, config: SandboxConfig): Promise&lt;ExecutionResult&gt; {
    // TODO: Create Docker container with restrictions
    // TODO: Mount allowed directories as volumes
    // TODO: Execute command
    // TODO: Collect output
    // TODO: Cleanup container
  }
}
</codeblock>
    <section><title>Exercise 2: Implement Security Incident Response</title></section>
    <p><b>Goal:</b> Build incident detection and response system.</p>
    <p><b>Requirements:</b>
1. Detect security incidents (multiple failed attempts, unusual patterns)
2. Classify severity
3. Trigger alerts
4. Implement automatic response (block user, require re-auth)
5. Generate incident reports</p>
    <p><b>Hints:</b>
- Track failed operations per user/IP
- Use sliding window for rate detection
- Integration with notification systems (email, Slack)</p>
    <section><title>Exercise 3: GDPR Compliance Features</title></section>
    <p><b>Goal:</b> Add GDPR compliance features for handling user data.</p>
    <p><b>Requirements:</b>
1. Implement data export (all user data in JSON)
2. Implement data deletion (right to be forgotten)
3. Add consent management (track consents)
4. Implement data retention policies (auto-delete old data)
5. Generate compliance reports</p>
    <p><b>Example:</b></p>
    <codeblock outputclass="language-typescript">export class GDPRCompliance {
  async exportUserData(userId: string): Promise&lt;UserDataExport&gt; {
    // Export all data for user
  }

  async deleteUserData(userId: string): Promise&lt;void&gt; {
    // Delete all user data
  }

  async trackConsent(userId: string, consentType: string): Promise&lt;void&gt; {
    // Record consent
  }
}
</codeblock>
    <section><title>Summary</title></section>
    <p>In this chapter, you built comprehensive security controls for your AI coding assistant.</p>
    <section><title>Key Concepts</title></section>
    <ol>
      <li>
        <b>Sandboxed Execution</b>
        - Restrict file access, commands, and resource usage
      </li>
      <li>
        <b>Credential Management</b>
        - Encrypted storage with AES-256-GCM
      </li>
      <li>
        <b>Input Validation</b>
        - Detect and prevent injection attacks
      </li>
      <li>
        <b>Rate Limiting</b>
        - Prevent resource exhaustion with token bucket
      </li>
      <li>
        <b>Privacy Filtering</b>
        - Remove sensitive data before AI processing
      </li>
      <li>
        <b>Audit Logging</b>
        - Complete forensic trail of all operations
      </li>
      <li>
        <b>Security Best Practices</b>
        - Production-ready security checklist
      </li>
    </ol>
    <section><title>Security Layers</title></section>
    <codeblock>User Input
    ↓
Input Validation (detect injection, sensitive data)
    ↓
Privacy Filter (redact secrets)
    ↓
Authorization (check permissions)
    ↓
Rate Limiting (check quotas)
    ↓
Sandboxed Execution (restricted environment)
    ↓
Audit Logging (record everything)
</codeblock>
    <section><title>Real-World Impact</title></section>
    <p><b>Before Security:</b></p>
    <codeblock>User: &quot;Delete old database backups&quot;
AI: [Executes: rm -rf /backups/*]
Result: ❌ All backups deleted including production
        ❌ No audit trail
        ❌ No approval required
</codeblock>
    <p><b>After Security:</b></p>
    <codeblock>User: &quot;Delete old database backups&quot;
AI: [Security checks]
    [Detects destructive operation]
    ⚠️  This will delete files in /backups/
    📋 Affected: 147 files (23 GB)
    🔒 Requires approval

User: [Types &apos;yes&apos;]
AI: [Sandboxed execution]
    [Only deletes files older than 90 days]
    [Logs to audit trail]
    ✓ Deleted 12 old backups (3.2 GB)
    ✓ Kept 135 recent backups (19.8 GB)
</codeblock>
    <p><b>Security Metrics:</b>
- 100% of destructive operations require approval
- 0% sensitive data leakage to AI
- Complete audit trail for compliance
- Budget controls prevent cost overruns
- Sandboxing prevents unauthorized access</p>
    <section><title>Part III Complete!</title></section>
    <p>You&apos;ve now completed all three chapters of Part III: Advanced Features:</p>
    <ol>
      <li>
        ✅
        <b>Chapter 7</b>
        : VCS Intelligence - AI-powered git workflows
      </li>
      <li>
        ✅
        <b>Chapter 8</b>
        : Interactive Modes - Natural language routing
      </li>
      <li>
        ✅
        <b>Chapter 9</b>
        : Security - Complete security framework
      </li>
    </ol>
    <section><title>Next Steps</title></section>
    <p>In <b>Part IV: Production Readiness</b>, you&apos;ll learn how to test, optimize, and monitor your AI coding assistant for production deployment.</p>
    <p><i>Chapter 9 | Security, Privacy, and Sandboxing | Complete</i></p>
  </body>
</topic>