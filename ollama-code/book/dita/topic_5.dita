<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE topic PUBLIC "-//OASIS//DTD DITA Topic//EN" "topic.dtd">
<topic id="topic_5">
  <title>Chapter 5: Streaming Architecture and Real-Time Responses</title>
  <body>
    <section><title>Introduction</title></section>
    <p>In Chapter 4, we built a powerful tool orchestration system that enables AI to execute actions. But there&apos;s a critical UX problem: <b>users are left waiting in the dark</b>.</p>
    <p>Imagine asking an AI assistant to &quot;analyze this codebase and create a refactoring plan.&quot; Without streaming:</p>
    <codeblock>User: &quot;Analyze this codebase and create a refactoring plan&quot;
[30 seconds of silence - user sees nothing]
[Suddenly, entire response appears at once]
AI: &quot;Here&apos;s my analysis...&quot; [5000 words]
</codeblock>
    <p>This creates several problems:</p>
    <ol>
      <li>
        <b>Poor UX</b>
        - Users don&apos;t know if the system is working or frozen
      </li>
      <li>
        <b>Lost Context</b>
        - Users can&apos;t start reading until everything is done
      </li>
      <li>
        <b>Wasted Time</b>
        - Users wait for the entire response before seeing anything
      </li>
      <li>
        <b>No Feedback</b>
        - Tool execution happens invisibly
      </li>
      <li>
        <b>No Control</b>
        - Users can&apos;t cancel if they see the response going wrong
      </li>
    </ol>
    <p><b>Streaming architecture</b> solves these problems by providing real-time feedback:</p>
    <codeblock>User: &quot;Analyze this codebase and create a refactoring plan&quot;
[Immediately] &quot;Analyzing codebase structure...&quot;
[1s] &quot;Found 47 TypeScript files in src/&quot;
[2s] &quot;Detecting patterns...&quot;
[3s] &quot;Identified 3 architectural concerns:&quot;
[4s] &quot;1. Circular dependencies in...&quot;
[User can start reading while AI continues generating]
</codeblock>
    <p>In this chapter, we&apos;ll build a complete streaming architecture that provides:</p>
    <ul>
      <li>
        <b>Token-by-token streaming</b>
        - Show AI responses as they&apos;re generated
      </li>
      <li>
        <b>Progress reporting</b>
        - Real-time updates on tool execution
      </li>
      <li>
        <b>Backpressure handling</b>
        - Prevent memory overflow
      </li>
      <li>
        <b>Cancellation support</b>
        - Allow users to stop operations
      </li>
      <li>
        <b>Error recovery</b>
        - Graceful handling of stream failures
      </li>
    </ul>
    <section><title>What You&apos;ll Learn</title></section>
    <p>By the end of this chapter, you&apos;ll understand:</p>
    <ol>
      <li>
        <b>Streaming Protocols</b>
        - Server-sent events, chunked encoding, WebSockets
      </li>
      <li>
        <b>Stream Processing</b>
        - Async iterators, transform streams, buffers
      </li>
      <li>
        <b>Progress Tracking</b>
        - Real-time status updates for long operations
      </li>
      <li>
        <b>Backpressure</b>
        - Handling fast producers and slow consumers
      </li>
      <li>
        <b>Cancellation</b>
        - Aborting operations gracefully
      </li>
      <li>
        <b>Error Recovery</b>
        - Handling stream failures
      </li>
      <li>
        <b>Multi-Turn Streaming</b>
        - Conversation context with streaming
      </li>
      <li>
        <b>Terminal Rendering</b>
        - Beautiful output in CLI applications
      </li>
    </ol>
    <section><title>5.1 Why Streaming?</title></section>
    <section><title>The Problem with Non-Streaming Responses</title></section>
    <p>Let&apos;s compare non-streaming vs streaming for a typical AI coding task:</p>
    <p><b>Non-Streaming (Traditional Approach):</b></p>
    <codeblock outputclass="language-typescript">async function generateCode(prompt: string): Promise&lt;string&gt; {
  const response = await aiProvider.chat({
    messages: [{ role: &apos;user&apos;, content: prompt }]
  });

  // User waits for entire response
  return response.content;
}

// Usage
console.log(&apos;Generating code...&apos;);
const code = await generateCode(&apos;Create a REST API for users&apos;);
console.log(code); // All at once after 10 seconds
</codeblock>
    <p><b>Timeline:</b></p>
    <codeblock>0s:  User sends request
     [10 seconds of silence]
10s: Entire response appears
</codeblock>
    <p><b>Problems:</b>
- ‚ùå No progress indication
- ‚ùå No partial results
- ‚ùå Poor perceived performance
- ‚ùå Cannot cancel
- ‚ùå High memory usage (buffer entire response)</p>
    <p><b>Streaming Approach:</b></p>
    <codeblock outputclass="language-typescript">async function* generateCodeStreaming(prompt: string): AsyncGenerator&lt;string&gt; {
  const stream = await aiProvider.streamChat({
    messages: [{ role: &apos;user&apos;, content: prompt }]
  });

  for await (const chunk of stream) {
    yield chunk.content;
  }
}

// Usage
console.log(&apos;Generating code...&apos;);
for await (const chunk of generateCodeStreaming(&apos;Create a REST API&apos;)) {
  process.stdout.write(chunk); // Show tokens as they arrive
}
</codeblock>
    <p><b>Timeline:</b></p>
    <codeblock>0s:   User sends request
0.1s: First tokens appear: &quot;Here&apos;s a REST API...&quot;
0.2s: More tokens: &quot;for user management...&quot;
0.5s: Continues streaming...
10s:  Final tokens complete
</codeblock>
    <p><b>Benefits:</b>
- ‚úÖ Immediate feedback (perceived as 10x faster)
- ‚úÖ Partial results available immediately
- ‚úÖ Better perceived performance
- ‚úÖ Can cancel mid-stream
- ‚úÖ Lower memory usage (process chunks incrementally)</p>
    <section><title>Performance Impact</title></section>
    <p>Let&apos;s quantify the UX improvement:</p>
    <codeblock outputclass="language-typescript">// Benchmark: Time until user sees first content

// Non-streaming
console.time(&apos;First content (non-streaming)&apos;);
const response = await generateCode(prompt);
console.log(response[0]); // First character
console.timeEnd(&apos;First content (non-streaming)&apos;);
// Output: First content (non-streaming): 8743ms

// Streaming
console.time(&apos;First content (streaming)&apos;);
const stream = generateCodeStreaming(prompt);
const firstChunk = await stream.next();
console.log(firstChunk.value);
console.timeEnd(&apos;First content (streaming)&apos;);
// Output: First content (streaming): 142ms

// Improvement: 8743ms ‚Üí 142ms (61x faster first content!)
</codeblock>
    <section><title>Real-World Use Cases</title></section>
    <p>Streaming is essential for:</p>
    <ol>
      <li>
        <b>Long-Form Content Generation</b>
      </li>
      <li>
        Documentation writing
      </li>
      <li>
        Code explanations
      </li>
      <li>
        <p>Refactoring plans</p>
      </li>
      <li>
        <p><b>Multi-Step Workflows</b></p>
      </li>
      <li>
        Tool execution progress
      </li>
      <li>
        Build/test output
      </li>
      <li>
        <p>File processing status</p>
      </li>
      <li>
        <p><b>Interactive Conversations</b></p>
      </li>
      <li>
        Back-and-forth dialogue
      </li>
      <li>
        Clarification questions
      </li>
      <li>
        <p>Iterative refinement</p>
      </li>
      <li>
        <p><b>Large Codebase Analysis</b></p>
      </li>
      <li>
        Search results
      </li>
      <li>
        Dependency analysis
      </li>
      <li>
        Code metrics
      </li>
    </ol>
    <section><title>5.2 Streaming Protocol Design</title></section>
    <section><title>Core Streaming Concepts</title></section>
    <p>A streaming protocol needs to handle:</p>
    <ol>
      <li>
        <b>Chunks</b>
        - Individual pieces of data
      </li>
      <li>
        <b>Events</b>
        - Different types of stream events
      </li>
      <li>
        <b>Completion</b>
        - Signal when stream ends
      </li>
      <li>
        <b>Errors</b>
        - Handle failures gracefully
      </li>
      <li>
        <b>Cancellation</b>
        - Allow aborting
      </li>
    </ol>
    <section><title>Stream Event Types</title></section>
    <codeblock outputclass="language-typescript">/**
 * Types of events in a streaming response
 */
export enum StreamEventType {
  // Content chunk from AI
  CONTENT = &apos;content&apos;,

  // Tool execution started
  TOOL_START = &apos;tool_start&apos;,

  // Tool execution progress
  TOOL_PROGRESS = &apos;tool_progress&apos;,

  // Tool execution completed
  TOOL_COMPLETE = &apos;tool_complete&apos;,

  // Tool execution failed
  TOOL_ERROR = &apos;tool_error&apos;,

  // Stream completed successfully
  DONE = &apos;done&apos;,

  // Stream error
  ERROR = &apos;error&apos;,

  // Metadata (model info, usage stats, etc.)
  METADATA = &apos;metadata&apos;
}

/**
 * Base stream event
 */
export interface StreamEvent {
  type: StreamEventType;
  timestamp: Date;
}

/**
 * Content event - AI generated text
 */
export interface ContentEvent extends StreamEvent {
  type: StreamEventType.CONTENT;
  content: string;
  delta?: string; // Incremental change (for efficiency)
}

/**
 * Tool start event
 */
export interface ToolStartEvent extends StreamEvent {
  type: StreamEventType.TOOL_START;
  toolName: string;
  toolId: string;
  parameters: any;
}

/**
 * Tool progress event
 */
export interface ToolProgressEvent extends StreamEvent {
  type: StreamEventType.TOOL_PROGRESS;
  toolId: string;
  progress: number; // 0-100
  message?: string;
}

/**
 * Tool complete event
 */
export interface ToolCompleteEvent extends StreamEvent {
  type: StreamEventType.TOOL_COMPLETE;
  toolId: string;
  result: any;
  durationMs: number;
}

/**
 * Tool error event
 */
export interface ToolErrorEvent extends StreamEvent {
  type: StreamEventType.TOOL_ERROR;
  toolId: string;
  error: {
    message: string;
    code?: string;
  };
}

/**
 * Done event - stream completed
 */
export interface DoneEvent extends StreamEvent {
  type: StreamEventType.DONE;
  metadata?: {
    tokensGenerated?: number;
    durationMs?: number;
    model?: string;
  };
}

/**
 * Error event - stream failed
 */
export interface ErrorEvent extends StreamEvent {
  type: StreamEventType.ERROR;
  error: {
    message: string;
    code?: string;
    recoverable: boolean;
  };
}

/**
 * Metadata event
 */
export interface MetadataEvent extends StreamEvent {
  type: StreamEventType.METADATA;
  metadata: {
    model?: string;
    provider?: string;
    [key: string]: any;
  };
}

/**
 * Union type of all stream events
 */
export type AnyStreamEvent =
  | ContentEvent
  | ToolStartEvent
  | ToolProgressEvent
  | ToolCompleteEvent
  | ToolErrorEvent
  | DoneEvent
  | ErrorEvent
  | MetadataEvent;
</codeblock>
    <section><title>Stream Producer Interface</title></section>
    <codeblock outputclass="language-typescript">/**
 * Stream producer - generates events
 */
export interface StreamProducer {
  /**
   * Start producing events
   */
  start(): AsyncGenerator&lt;AnyStreamEvent, void, unknown&gt;;

  /**
   * Cancel the stream
   */
  cancel(): Promise&lt;void&gt;;

  /**
   * Check if stream is active
   */
  isActive(): boolean;
}

/**
 * Stream consumer - processes events
 */
export interface StreamConsumer {
  /**
   * Handle a stream event
   */
  onEvent(event: AnyStreamEvent): Promise&lt;void&gt; | void;

  /**
   * Stream completed successfully
   */
  onComplete?(metadata?: any): Promise&lt;void&gt; | void;

  /**
   * Stream failed with error
   */
  onError?(error: Error): Promise&lt;void&gt; | void;
}
</codeblock>
    <section><title>Basic Stream Implementation</title></section>
    <codeblock outputclass="language-typescript">/**
 * Basic stream implementation
 */
export class StreamProcessor {
  private producer: StreamProducer;
  private consumers: StreamConsumer[] = [];
  private active = false;
  private abortController: AbortController;

  constructor(producer: StreamProducer) {
    this.producer = producer;
    this.abortController = new AbortController();
  }

  /**
   * Add a consumer
   */
  addConsumer(consumer: StreamConsumer): void {
    this.consumers.push(consumer);
  }

  /**
   * Start streaming
   */
  async start(): Promise&lt;void&gt; {
    if (this.active) {
      throw new Error(&apos;Stream already active&apos;);
    }

    this.active = true;

    try {
      // Get event stream from producer
      const stream = this.producer.start();

      // Process events
      for await (const event of stream) {
        // Check if cancelled
        if (this.abortController.signal.aborted) {
          break;
        }

        // Send to all consumers
        await this.broadcast(event);

        // Handle stream completion
        if (event.type === StreamEventType.DONE) {
          await this.complete(event.metadata);
          break;
        }

        // Handle stream error
        if (event.type === StreamEventType.ERROR) {
          throw new Error(event.error.message);
        }
      }
    } catch (error: any) {
      await this.handleError(error);
    } finally {
      this.active = false;
    }
  }

  /**
   * Cancel the stream
   */
  async cancel(): Promise&lt;void&gt; {
    this.abortController.abort();
    await this.producer.cancel();
    this.active = false;
  }

  /**
   * Broadcast event to all consumers
   */
  private async broadcast(event: AnyStreamEvent): Promise&lt;void&gt; {
    const promises = this.consumers.map(consumer =&gt;
      consumer.onEvent(event)
    );
    await Promise.all(promises);
  }

  /**
   * Handle stream completion
   */
  private async complete(metadata?: any): Promise&lt;void&gt; {
    const promises = this.consumers
      .filter(c =&gt; c.onComplete)
      .map(c =&gt; c.onComplete!(metadata));

    await Promise.all(promises);
  }

  /**
   * Handle stream error
   */
  private async handleError(error: Error): Promise&lt;void&gt; {
    const promises = this.consumers
      .filter(c =&gt; c.onError)
      .map(c =&gt; c.onError!(error));

    await Promise.all(promises);
  }

  /**
   * Check if stream is active
   */
  isActive(): boolean {
    return this.active;
  }
}
</codeblock>
    <section><title>Usage Example</title></section>
    <codeblock outputclass="language-typescript">// Define a producer
class AIResponseProducer implements StreamProducer {
  private cancelled = false;

  async* start(): AsyncGenerator&lt;AnyStreamEvent&gt; {
    yield {
      type: StreamEventType.METADATA,
      timestamp: new Date(),
      metadata: { model: &apos;claude-3-5-sonnet&apos;, provider: &apos;anthropic&apos; }
    };

    // Simulate streaming content
    const words = [&apos;Hello&apos;, &apos; world&apos;, &apos;!&apos;, &apos; How&apos;, &apos; can&apos;, &apos; I&apos;, &apos; help?&apos;];
    for (const word of words) {
      if (this.cancelled) break;

      yield {
        type: StreamEventType.CONTENT,
        timestamp: new Date(),
        content: word,
        delta: word
      };

      await new Promise(resolve =&gt; setTimeout(resolve, 100));
    }

    yield {
      type: StreamEventType.DONE,
      timestamp: new Date(),
      metadata: { tokensGenerated: 7, durationMs: 700 }
    };
  }

  async cancel(): Promise&lt;void&gt; {
    this.cancelled = true;
  }

  isActive(): boolean {
    return !this.cancelled;
  }
}

// Define a consumer
class TerminalConsumer implements StreamConsumer {
  private buffer = &apos;&apos;;

  onEvent(event: AnyStreamEvent): void {
    switch (event.type) {
      case StreamEventType.CONTENT:
        this.buffer += event.content;
        process.stdout.write(event.content);
        break;

      case StreamEventType.METADATA:
        console.log(`[Using ${event.metadata.model}]`);
        break;

      case StreamEventType.DONE:
        console.log(`\n[Done in ${event.metadata?.durationMs}ms]`);
        break;
    }
  }

  onComplete(): void {
    console.log(&apos;\nStream completed successfully&apos;);
  }

  onError(error: Error): void {
    console.error(`\nStream error: ${error.message}`);
  }
}

// Use the stream
const producer = new AIResponseProducer();
const processor = new StreamProcessor(producer);
processor.addConsumer(new TerminalConsumer());

await processor.start();

// Output:
// [Using claude-3-5-sonnet]
// Hello world! How can I help?
// [Done in 700ms]
// Stream completed successfully
</codeblock>
    <section><title>5.3 Buffer Management</title></section>
    <p>Streaming involves managing buffers to handle data flow efficiently. Improper buffer management leads to memory leaks or performance issues.</p>
    <section><title>Buffer Strategies</title></section>
    <codeblock outputclass="language-typescript">/**
 * Buffer strategy for stream processing
 */
export enum BufferStrategy {
  // No buffering - process immediately
  NONE = &apos;none&apos;,

  // Fixed size buffer
  FIXED = &apos;fixed&apos;,

  // Dynamic buffer that grows as needed
  DYNAMIC = &apos;dynamic&apos;,

  // Sliding window - keep only recent data
  SLIDING = &apos;sliding&apos;
}

/**
 * Stream buffer for managing chunks
 */
export class StreamBuffer {
  private buffer: string[] = [];
  private maxSize: number;
  private strategy: BufferStrategy;
  private bytesBuffered = 0;
  private maxBytes: number;

  constructor(
    strategy: BufferStrategy = BufferStrategy.DYNAMIC,
    options: BufferOptions = {}
  ) {
    this.strategy = strategy;
    this.maxSize = options.maxSize || 1000;
    this.maxBytes = options.maxBytes || 1024 * 1024; // 1MB default
  }

  /**
   * Add chunk to buffer
   */
  add(chunk: string): void {
    const chunkBytes = Buffer.byteLength(chunk, &apos;utf8&apos;);

    // Check byte limit
    if (this.bytesBuffered + chunkBytes &gt; this.maxBytes) {
      this.evict(chunkBytes);
    }

    this.buffer.push(chunk);
    this.bytesBuffered += chunkBytes;

    // Apply strategy
    this.applyStrategy();
  }

  /**
   * Get buffered content
   */
  get(): string {
    return this.buffer.join(&apos;&apos;);
  }

  /**
   * Get last N chunks
   */
  getLast(n: number): string {
    return this.buffer.slice(-n).join(&apos;&apos;);
  }

  /**
   * Clear buffer
   */
  clear(): void {
    this.buffer = [];
    this.bytesBuffered = 0;
  }

  /**
   * Get buffer size
   */
  size(): number {
    return this.buffer.length;
  }

  /**
   * Get bytes buffered
   */
  bytes(): number {
    return this.bytesBuffered;
  }

  /**
   * Apply buffer strategy
   */
  private applyStrategy(): void {
    switch (this.strategy) {
      case BufferStrategy.NONE:
        // Keep only last chunk
        if (this.buffer.length &gt; 1) {
          const removed = this.buffer.shift()!;
          this.bytesBuffered -= Buffer.byteLength(removed, &apos;utf8&apos;);
        }
        break;

      case BufferStrategy.FIXED:
        // Keep fixed number of chunks
        while (this.buffer.length &gt; this.maxSize) {
          const removed = this.buffer.shift()!;
          this.bytesBuffered -= Buffer.byteLength(removed, &apos;utf8&apos;);
        }
        break;

      case BufferStrategy.SLIDING:
        // Keep only recent chunks (half of max size)
        const target = Math.floor(this.maxSize / 2);
        while (this.buffer.length &gt; target) {
          const removed = this.buffer.shift()!;
          this.bytesBuffered -= Buffer.byteLength(removed, &apos;utf8&apos;);
        }
        break;

      case BufferStrategy.DYNAMIC:
        // No limit, but respect maxBytes
        break;
    }
  }

  /**
   * Evict old chunks to make room
   */
  private evict(requiredBytes: number): void {
    while (this.bytesBuffered + requiredBytes &gt; this.maxBytes &amp;&amp; this.buffer.length &gt; 0) {
      const removed = this.buffer.shift()!;
      this.bytesBuffered -= Buffer.byteLength(removed, &apos;utf8&apos;);
    }
  }
}

interface BufferOptions {
  maxSize?: number;
  maxBytes?: number;
}
</codeblock>
    <section><title>Backpressure Handling</title></section>
    <p>Backpressure occurs when the producer generates data faster than the consumer can process it.</p>
    <codeblock outputclass="language-typescript">/**
 * Backpressure controller
 */
export class BackpressureController {
  private bufferSize = 0;
  private maxBufferSize: number;
  private paused = false;
  private pauseCallback?: () =&gt; void;
  private resumeCallback?: () =&gt; void;

  constructor(maxBufferSize: number = 100) {
    this.maxBufferSize = maxBufferSize;
  }

  /**
   * Add item to buffer
   */
  async add(): Promise&lt;void&gt; {
    this.bufferSize++;

    // Check if we need to pause producer
    if (this.bufferSize &gt;= this.maxBufferSize &amp;&amp; !this.paused) {
      this.paused = true;
      if (this.pauseCallback) {
        this.pauseCallback();
      }

      // Wait until consumer catches up
      await this.waitForResume();
    }
  }

  /**
   * Remove item from buffer
   */
  remove(): void {
    this.bufferSize--;

    // Check if we can resume producer
    if (this.bufferSize &lt; this.maxBufferSize / 2 &amp;&amp; this.paused) {
      this.paused = false;
      if (this.resumeCallback) {
        this.resumeCallback();
      }
    }
  }

  /**
   * Set callbacks
   */
  onPause(callback: () =&gt; void): void {
    this.pauseCallback = callback;
  }

  onResume(callback: () =&gt; void): void {
    this.resumeCallback = callback;
  }

  /**
   * Wait for resume signal
   */
  private waitForResume(): Promise&lt;void&gt; {
    return new Promise((resolve) =&gt; {
      const checkInterval = setInterval(() =&gt; {
        if (!this.paused) {
          clearInterval(checkInterval);
          resolve();
        }
      }, 10);
    });
  }

  /**
   * Get current buffer size
   */
  getBufferSize(): number {
    return this.bufferSize;
  }

  /**
   * Check if paused
   */
  isPaused(): boolean {
    return this.paused;
  }
}
</codeblock>
    <section><title>Stream with Backpressure</title></section>
    <codeblock outputclass="language-typescript">/**
 * Enhanced stream processor with backpressure
 */
export class BackpressureStreamProcessor extends StreamProcessor {
  private backpressure: BackpressureController;
  private buffer: StreamBuffer;

  constructor(
    producer: StreamProducer,
    options: BackpressureOptions = {}
  ) {
    super(producer);
    this.backpressure = new BackpressureController(options.maxBufferSize);
    this.buffer = new StreamBuffer(options.bufferStrategy, options.buffer);

    // Setup backpressure callbacks
    this.backpressure.onPause(() =&gt; {
      console.warn(&apos;‚ö†Ô∏è  Backpressure: pausing producer (buffer full)&apos;);
    });

    this.backpressure.onResume(() =&gt; {
      console.log(&apos;‚úì Backpressure: resuming producer&apos;);
    });
  }

  /**
   * Broadcast event with backpressure control
   */
  protected async broadcast(event: AnyStreamEvent): Promise&lt;void&gt; {
    // Add to backpressure controller
    await this.backpressure.add();

    try {
      // Buffer content events
      if (event.type === StreamEventType.CONTENT) {
        this.buffer.add(event.content);
      }

      // Send to consumers
      await super.broadcast(event);
    } finally {
      // Remove from backpressure controller
      this.backpressure.remove();
    }
  }

  /**
   * Get buffered content
   */
  getBuffered(): string {
    return this.buffer.get();
  }

  /**
   * Get backpressure stats
   */
  getStats(): BackpressureStats {
    return {
      bufferSize: this.backpressure.getBufferSize(),
      isPaused: this.backpressure.isPaused(),
      bytesBuffered: this.buffer.bytes(),
      chunksBuffered: this.buffer.size()
    };
  }
}

interface BackpressureOptions {
  maxBufferSize?: number;
  bufferStrategy?: BufferStrategy;
  buffer?: BufferOptions;
}

interface BackpressureStats {
  bufferSize: number;
  isPaused: boolean;
  bytesBuffered: number;
  chunksBuffered: number;
}
</codeblock>
    <section><title>5.4 Progress Reporting</title></section>
    <p>For long-running operations, users need to know what&apos;s happening. Progress reporting provides real-time status updates.</p>
    <section><title>Progress Tracker</title></section>
    <codeblock outputclass="language-typescript">/**
 * Progress tracker for operations
 */
export class ProgressTracker {
  private current = 0;
  private total: number;
  private message = &apos;&apos;;
  private startTime: Date;
  private stages: ProgressStage[] = [];
  private currentStageIndex = 0;

  constructor(total: number, stages?: ProgressStage[]) {
    this.total = total;
    this.startTime = new Date();
    this.stages = stages || [];
  }

  /**
   * Update progress
   */
  update(current: number, message?: string): ProgressUpdate {
    this.current = Math.min(current, this.total);
    if (message) {
      this.message = message;
    }

    return this.getProgress();
  }

  /**
   * Increment progress
   */
  increment(amount: number = 1, message?: string): ProgressUpdate {
    return this.update(this.current + amount, message);
  }

  /**
   * Start next stage
   */
  nextStage(): ProgressUpdate {
    if (this.currentStageIndex &lt; this.stages.length - 1) {
      this.currentStageIndex++;
      this.message = this.stages[this.currentStageIndex].name;
    }
    return this.getProgress();
  }

  /**
   * Get current progress
   */
  getProgress(): ProgressUpdate {
    const elapsed = Date.now() - this.startTime.getTime();
    const percentage = (this.current / this.total) * 100;

    // Estimate remaining time
    let estimatedRemaining: number | undefined;
    if (this.current &gt; 0) {
      const rate = this.current / elapsed; // items per ms
      const remaining = this.total - this.current;
      estimatedRemaining = remaining / rate;
    }

    return {
      current: this.current,
      total: this.total,
      percentage: Math.min(percentage, 100),
      message: this.message,
      elapsed,
      estimatedRemaining,
      stage: this.stages[this.currentStageIndex]
    };
  }

  /**
   * Mark as complete
   */
  complete(message?: string): ProgressUpdate {
    this.current = this.total;
    if (message) {
      this.message = message;
    }
    return this.getProgress();
  }

  /**
   * Check if complete
   */
  isComplete(): boolean {
    return this.current &gt;= this.total;
  }
}

interface ProgressStage {
  name: string;
  weight: number; // Relative weight (for multi-stage progress)
}

interface ProgressUpdate {
  current: number;
  total: number;
  percentage: number;
  message: string;
  elapsed: number;
  estimatedRemaining?: number;
  stage?: ProgressStage;
}
</codeblock>
    <section><title>Progress Stream Events</title></section>
    <codeblock outputclass="language-typescript">/**
 * Emit progress events during streaming
 */
export class ProgressStreamProducer implements StreamProducer {
  private cancelled = false;
  private tracker: ProgressTracker;

  constructor(private operation: () =&gt; Promise&lt;void&gt;) {
    this.tracker = new ProgressTracker(100, [
      { name: &apos;Initializing&apos;, weight: 10 },
      { name: &apos;Processing&apos;, weight: 70 },
      { name: &apos;Finalizing&apos;, weight: 20 }
    ]);
  }

  async* start(): AsyncGenerator&lt;AnyStreamEvent&gt; {
    try {
      // Stage 1: Initialize
      yield this.createProgressEvent(this.tracker.update(0, &apos;Initializing...&apos;));
      await this.sleep(500);

      // Stage 2: Process
      yield this.createProgressEvent(this.tracker.nextStage());

      for (let i = 10; i &lt;= 80; i += 10) {
        if (this.cancelled) break;

        yield this.createProgressEvent(
          this.tracker.update(i, `Processing ${i}%...`)
        );

        await this.sleep(200);
      }

      // Stage 3: Finalize
      yield this.createProgressEvent(this.tracker.nextStage());
      await this.sleep(300);

      // Complete
      yield this.createProgressEvent(
        this.tracker.complete(&apos;Operation complete&apos;)
      );

      yield {
        type: StreamEventType.DONE,
        timestamp: new Date(),
        metadata: { durationMs: this.tracker.getProgress().elapsed }
      };
    } catch (error: any) {
      yield {
        type: StreamEventType.ERROR,
        timestamp: new Date(),
        error: {
          message: error.message,
          recoverable: false
        }
      };
    }
  }

  async cancel(): Promise&lt;void&gt; {
    this.cancelled = true;
  }

  isActive(): boolean {
    return !this.cancelled;
  }

  private createProgressEvent(update: ProgressUpdate): ToolProgressEvent {
    return {
      type: StreamEventType.TOOL_PROGRESS,
      timestamp: new Date(),
      toolId: &apos;operation&apos;,
      progress: update.percentage,
      message: update.message
    };
  }

  private sleep(ms: number): Promise&lt;void&gt; {
    return new Promise(resolve =&gt; setTimeout(resolve, ms));
  }
}
</codeblock>
    <section><title>Progress Bar Renderer</title></section>
    <codeblock outputclass="language-typescript">/**
 * Terminal progress bar
 */
export class ProgressBar {
  private width: number;
  private lastRendered = &apos;&apos;;

  constructor(width: number = 40) {
    this.width = width;
  }

  /**
   * Render progress bar
   */
  render(progress: ProgressUpdate): string {
    const percentage = Math.min(progress.percentage, 100);
    const filled = Math.floor((percentage / 100) * this.width);
    const empty = this.width - filled;

    // Build bar
    const bar = &apos;‚ñà&apos;.repeat(filled) + &apos;‚ñë&apos;.repeat(empty);

    // Build line
    const line = [
      `[${bar}]`,
      `${percentage.toFixed(1)}%`,
      progress.message
    ];

    // Add time estimates
    if (progress.estimatedRemaining) {
      const seconds = Math.ceil(progress.estimatedRemaining / 1000);
      line.push(`~${seconds}s remaining`);
    }

    const rendered = line.join(&apos; &apos;);

    // Clear previous line and render new one
    if (this.lastRendered) {
      process.stdout.write(&apos;\r&apos; + &apos; &apos;.repeat(this.lastRendered.length) + &apos;\r&apos;);
    }

    process.stdout.write(rendered);
    this.lastRendered = rendered;

    return rendered;
  }

  /**
   * Clear progress bar
   */
  clear(): void {
    if (this.lastRendered) {
      process.stdout.write(&apos;\r&apos; + &apos; &apos;.repeat(this.lastRendered.length) + &apos;\r&apos;);
      this.lastRendered = &apos;&apos;;
    }
  }

  /**
   * Complete and show final state
   */
  complete(message?: string): void {
    this.render({
      current: 100,
      total: 100,
      percentage: 100,
      message: message || &apos;Complete&apos;,
      elapsed: 0
    });
    process.stdout.write(&apos;\n&apos;);
    this.lastRendered = &apos;&apos;;
  }
}
</codeblock>
    <section><title>Usage Example</title></section>
    <codeblock outputclass="language-typescript">// Progress consumer
class ProgressConsumer implements StreamConsumer {
  private progressBar = new ProgressBar(40);

  onEvent(event: AnyStreamEvent): void {
    if (event.type === StreamEventType.TOOL_PROGRESS) {
      this.progressBar.render({
        current: event.progress,
        total: 100,
        percentage: event.progress,
        message: event.message || &apos;&apos;,
        elapsed: 0
      });
    } else if (event.type === StreamEventType.DONE) {
      this.progressBar.complete(&apos;‚úì Done!&apos;);
    }
  }
}

// Use it
const producer = new ProgressStreamProducer(async () =&gt; {
  // Your long operation
});

const processor = new StreamProcessor(producer);
processor.addConsumer(new ProgressConsumer());

await processor.start();

// Output (animated):
// [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 50.0% Processing 50%... ~3s remaining
// [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà] 100.0% ‚úì Done!
</codeblock>
    <section><title>5.5 Cancellation Support</title></section>
    <p>Users should be able to cancel long-running operations. Let&apos;s implement robust cancellation.</p>
    <section><title>Cancellation Token</title></section>
    <codeblock outputclass="language-typescript">/**
 * Cancellation token for aborting operations
 */
export class CancellationToken {
  private _cancelled = false;
  private callbacks: Array&lt;() =&gt; void&gt; = [];
  private reason?: string;

  /**
   * Check if cancelled
   */
  get isCancelled(): boolean {
    return this._cancelled;
  }

  /**
   * Cancel the operation
   */
  cancel(reason?: string): void {
    if (this._cancelled) return;

    this._cancelled = true;
    this.reason = reason;

    // Notify all callbacks
    for (const callback of this.callbacks) {
      try {
        callback();
      } catch (error) {
        console.error(&apos;Error in cancellation callback:&apos;, error);
      }
    }

    this.callbacks = [];
  }

  /**
   * Register callback for cancellation
   */
  onCancelled(callback: () =&gt; void): void {
    if (this._cancelled) {
      callback();
    } else {
      this.callbacks.push(callback);
    }
  }

  /**
   * Throw if cancelled
   */
  throwIfCancelled(): void {
    if (this._cancelled) {
      throw new CancellationError(this.reason || &apos;Operation cancelled&apos;);
    }
  }

  /**
   * Get cancellation reason
   */
  getReason(): string | undefined {
    return this.reason;
  }
}

/**
 * Cancellation error
 */
export class CancellationError extends Error {
  constructor(message: string) {
    super(message);
    this.name = &apos;CancellationError&apos;;
  }
}
</codeblock>
    <section><title>Cancellable Stream</title></section>
    <codeblock outputclass="language-typescript">/**
 * Stream with cancellation support
 */
export class CancellableStreamProcessor extends BackpressureStreamProcessor {
  private cancellationToken: CancellationToken;

  constructor(
    producer: StreamProducer,
    options: BackpressureOptions = {}
  ) {
    super(producer, options);
    this.cancellationToken = new CancellationToken();

    // Register cancellation handler
    this.cancellationToken.onCancelled(() =&gt; {
      console.log(&apos;üõë Stream cancelled by user&apos;);
      this.producer.cancel();
    });
  }

  /**
   * Start streaming with cancellation support
   */
  async start(): Promise&lt;void&gt; {
    try {
      await super.start();
    } catch (error: any) {
      if (error instanceof CancellationError) {
        // Handle graceful cancellation
        await this.handleCancellation(error);
      } else {
        throw error;
      }
    }
  }

  /**
   * Cancel the stream
   */
  async cancel(reason?: string): Promise&lt;void&gt; {
    this.cancellationToken.cancel(reason);
    await super.cancel();
  }

  /**
   * Check cancellation token periodically
   */
  protected async broadcast(event: AnyStreamEvent): Promise&lt;void&gt; {
    // Check if cancelled before processing
    this.cancellationToken.throwIfCancelled();

    await super.broadcast(event);
  }

  /**
   * Handle graceful cancellation
   */
  private async handleCancellation(error: CancellationError): Promise&lt;void&gt; {
    // Notify consumers of cancellation
    const cancellationEvent: ErrorEvent = {
      type: StreamEventType.ERROR,
      timestamp: new Date(),
      error: {
        message: error.message,
        code: &apos;CANCELLED&apos;,
        recoverable: false
      }
    };

    await this.broadcast(cancellationEvent);
  }

  /**
   * Get cancellation token (for external cancellation)
   */
  getCancellationToken(): CancellationToken {
    return this.cancellationToken;
  }
}
</codeblock>
    <section><title>Keyboard Cancellation</title></section>
    <codeblock outputclass="language-typescript">/**
 * Enable Ctrl+C cancellation
 */
export class KeyboardCancellation {
  private cancellationToken: CancellationToken;
  private listener?: NodeJS.SignalsListener;

  constructor(cancellationToken: CancellationToken) {
    this.cancellationToken = cancellationToken;
  }

  /**
   * Enable keyboard cancellation
   */
  enable(): void {
    this.listener = () =&gt; {
      console.log(&apos;\n\nüõë Cancelling operation (Ctrl+C pressed)...&apos;);
      this.cancellationToken.cancel(&apos;User pressed Ctrl+C&apos;);

      // Remove listener to allow force quit on second Ctrl+C
      if (this.listener) {
        process.off(&apos;SIGINT&apos;, this.listener);
      }

      // Set timeout to force quit if graceful shutdown fails
      setTimeout(() =&gt; {
        console.error(&apos;‚ùå Force quitting (graceful shutdown timed out)&apos;);
        process.exit(1);
      }, 5000);
    };

    process.on(&apos;SIGINT&apos;, this.listener);
  }

  /**
   * Disable keyboard cancellation
   */
  disable(): void {
    if (this.listener) {
      process.off(&apos;SIGINT&apos;, this.listener);
      this.listener = undefined;
    }
  }
}
</codeblock>
    <section><title>Usage Example</title></section>
    <codeblock outputclass="language-typescript">// Create cancellable stream
const producer = new ProgressStreamProducer(async () =&gt; {
  // Long operation
});

const processor = new CancellableStreamProcessor(producer);
const cancellationToken = processor.getCancellationToken();

// Enable Ctrl+C cancellation
const keyboard = new KeyboardCancellation(cancellationToken);
keyboard.enable();

// Start streaming
try {
  await processor.start();
} catch (error) {
  if (error instanceof CancellationError) {
    console.log(&apos;‚úì Operation cancelled gracefully&apos;);
  } else {
    throw error;
  }
} finally {
  keyboard.disable();
}
</codeblock>
    <section><title>5.6 Error Recovery in Streams</title></section>
    <p>Streams can fail in various ways. Robust error recovery ensures graceful degradation.</p>
    <section><title>Error Recovery Strategy</title></section>
    <codeblock outputclass="language-typescript">/**
 * Error recovery strategy
 */
export enum RecoveryStrategy {
  // Fail immediately
  FAIL_FAST = &apos;fail_fast&apos;,

  // Retry with backoff
  RETRY = &apos;retry&apos;,

  // Skip error and continue
  CONTINUE = &apos;continue&apos;,

  // Use fallback
  FALLBACK = &apos;fallback&apos;
}

/**
 * Error recovery handler
 */
export class ErrorRecoveryHandler {
  private strategy: RecoveryStrategy;
  private maxRetries: number;
  private retryDelay: number;

  constructor(
    strategy: RecoveryStrategy = RecoveryStrategy.RETRY,
    options: RecoveryOptions = {}
  ) {
    this.strategy = strategy;
    this.maxRetries = options.maxRetries || 3;
    this.retryDelay = options.retryDelayMs || 1000;
  }

  /**
   * Handle stream error
   */
  async handle(
    error: Error,
    context: ErrorContext,
    retryFn: () =&gt; Promise&lt;any&gt;
  ): Promise&lt;RecoveryResult&gt; {
    switch (this.strategy) {
      case RecoveryStrategy.FAIL_FAST:
        return { recovered: false, error };

      case RecoveryStrategy.RETRY:
        return await this.retry(error, context, retryFn);

      case RecoveryStrategy.CONTINUE:
        console.warn(`‚ö†Ô∏è  Error in stream (continuing): ${error.message}`);
        return { recovered: true };

      case RecoveryStrategy.FALLBACK:
        return await this.fallback(error, context);

      default:
        return { recovered: false, error };
    }
  }

  /**
   * Retry with exponential backoff
   */
  private async retry(
    error: Error,
    context: ErrorContext,
    retryFn: () =&gt; Promise&lt;any&gt;
  ): Promise&lt;RecoveryResult&gt; {
    let lastError = error;

    for (let attempt = 1; attempt &lt;= this.maxRetries; attempt++) {
      console.warn(
        `‚ö†Ô∏è  Stream error (attempt ${attempt}/${this.maxRetries}): ${error.message}`
      );

      // Calculate delay with exponential backoff
      const delay = this.retryDelay * Math.pow(2, attempt - 1);
      await this.sleep(delay);

      try {
        await retryFn();
        console.log(`‚úì Recovered after ${attempt} attempts`);
        return { recovered: true, retriesAttempted: attempt };
      } catch (retryError: any) {
        lastError = retryError;
      }
    }

    return {
      recovered: false,
      error: lastError,
      retriesAttempted: this.maxRetries
    };
  }

  /**
   * Use fallback
   */
  private async fallback(
    error: Error,
    context: ErrorContext
  ): Promise&lt;RecoveryResult&gt; {
    console.warn(`‚ö†Ô∏è  Using fallback due to error: ${error.message}`);

    // Return partial results if available
    if (context.partialResults) {
      return {
        recovered: true,
        fallbackUsed: true,
        data: context.partialResults
      };
    }

    return {
      recovered: true,
      fallbackUsed: true,
      data: { message: &apos;Fallback response - original request failed&apos; }
    };
  }

  private sleep(ms: number): Promise&lt;void&gt; {
    return new Promise(resolve =&gt; setTimeout(resolve, ms));
  }
}

interface RecoveryOptions {
  maxRetries?: number;
  retryDelayMs?: number;
}

interface ErrorContext {
  eventType: StreamEventType;
  partialResults?: any;
  metadata?: any;
}

interface RecoveryResult {
  recovered: boolean;
  error?: Error;
  retriesAttempted?: number;
  fallbackUsed?: boolean;
  data?: any;
}
</codeblock>
    <section><title>Resilient Stream Processor</title></section>
    <codeblock outputclass="language-typescript">/**
 * Stream processor with error recovery
 */
export class ResilientStreamProcessor extends CancellableStreamProcessor {
  private errorHandler: ErrorRecoveryHandler;
  private partialResults: any[] = [];

  constructor(
    producer: StreamProducer,
    options: ResilientStreamOptions = {}
  ) {
    super(producer, options);
    this.errorHandler = new ErrorRecoveryHandler(
      options.recoveryStrategy,
      options.recovery
    );
  }

  /**
   * Start streaming with error recovery
   */
  async start(): Promise&lt;void&gt; {
    try {
      await super.start();
    } catch (error: any) {
      // Attempt recovery
      const result = await this.errorHandler.handle(
        error,
        {
          eventType: StreamEventType.ERROR,
          partialResults: this.partialResults
        },
        async () =&gt; {
          // Retry by restarting stream
          await super.start();
        }
      );

      if (!result.recovered) {
        throw result.error || error;
      }

      // Recovery successful
      if (result.fallbackUsed &amp;&amp; result.data) {
        // Emit fallback data
        await this.broadcast({
          type: StreamEventType.CONTENT,
          timestamp: new Date(),
          content: JSON.stringify(result.data)
        });
      }
    }
  }

  /**
   * Broadcast event and collect partial results
   */
  protected async broadcast(event: AnyStreamEvent): Promise&lt;void&gt; {
    // Collect partial results for error recovery
    if (event.type === StreamEventType.CONTENT) {
      this.partialResults.push(event.content);
    } else if (event.type === StreamEventType.TOOL_COMPLETE) {
      this.partialResults.push(event.result);
    }

    try {
      await super.broadcast(event);
    } catch (error: any) {
      // Handle consumer errors gracefully
      console.error(`Error in consumer: ${error.message}`);
      // Continue processing other events
    }
  }

  /**
   * Get partial results
   */
  getPartialResults(): any[] {
    return this.partialResults;
  }
}

interface ResilientStreamOptions extends BackpressureOptions {
  recoveryStrategy?: RecoveryStrategy;
  recovery?: RecoveryOptions;
}
</codeblock>
    <section><title>5.7 Terminal Output Streaming</title></section>
    <p>Beautiful terminal output makes streaming feel professional. Let&apos;s implement rich terminal rendering.</p>
    <section><title>Terminal Formatter</title></section>
    <codeblock outputclass="language-typescript">/**
 * Terminal output formatter
 */
export class TerminalFormatter {
  private colors = {
    reset: &apos;\x1b[0m&apos;,
    bright: &apos;\x1b[1m&apos;,
    dim: &apos;\x1b[2m&apos;,
    red: &apos;\x1b[31m&apos;,
    green: &apos;\x1b[32m&apos;,
    yellow: &apos;\x1b[33m&apos;,
    blue: &apos;\x1b[34m&apos;,
    magenta: &apos;\x1b[35m&apos;,
    cyan: &apos;\x1b[36m&apos;,
    gray: &apos;\x1b[90m&apos;
  };

  /**
   * Format text with color
   */
  color(text: string, color: keyof typeof this.colors): string {
    return `${this.colors[color]}${text}${this.colors.reset}`;
  }

  /**
   * Format success message
   */
  success(message: string): string {
    return `${this.colors.green}‚úì${this.colors.reset} ${message}`;
  }

  /**
   * Format error message
   */
  error(message: string): string {
    return `${this.colors.red}‚úó${this.colors.reset} ${message}`;
  }

  /**
   * Format warning message
   */
  warning(message: string): string {
    return `${this.colors.yellow}‚ö†${this.colors.reset} ${message}`;
  }

  /**
   * Format info message
   */
  info(message: string): string {
    return `${this.colors.blue}‚Ñπ${this.colors.reset} ${message}`;
  }

  /**
   * Format section header
   */
  header(text: string): string {
    return `\n${this.colors.bright}${text}${this.colors.reset}\n${&apos;‚îÄ&apos;.repeat(text.length)}`;
  }

  /**
   * Format code block
   */
  code(text: string, language?: string): string {
    const lines = text.split(&apos;\n&apos;);
    const formatted = lines.map(line =&gt;
      `${this.colors.gray}‚îÇ${this.colors.reset} ${line}`
    ).join(&apos;\n&apos;);

    const lang = language ? ` ${language}` : &apos;&apos;;
    return `${this.colors.gray}‚îå‚îÄ${lang}\n${formatted}\n‚îî‚îÄ${this.colors.reset}`;
  }

  /**
   * Format list item
   */
  listItem(text: string, level: number = 0): string {
    const indent = &apos;  &apos;.repeat(level);
    return `${indent}${this.colors.cyan}‚Ä¢${this.colors.reset} ${text}`;
  }

  /**
   * Spinner frames
   */
  private spinnerFrames = [&apos;‚†ã&apos;, &apos;‚†ô&apos;, &apos;‚†π&apos;, &apos;‚†∏&apos;, &apos;‚†º&apos;, &apos;‚†¥&apos;, &apos;‚†¶&apos;, &apos;‚†ß&apos;, &apos;‚†á&apos;, &apos;‚†è&apos;];
  private spinnerIndex = 0;

  /**
   * Get next spinner frame
   */
  spinner(): string {
    const frame = this.spinnerFrames[this.spinnerIndex];
    this.spinnerIndex = (this.spinnerIndex + 1) % this.spinnerFrames.length;
    return `${this.colors.cyan}${frame}${this.colors.reset}`;
  }

  /**
   * Clear current line
   */
  clearLine(): void {
    process.stdout.write(&apos;\r\x1b[K&apos;);
  }

  /**
   * Move cursor up
   */
  cursorUp(lines: number = 1): void {
    process.stdout.write(`\x1b[${lines}A`);
  }

  /**
   * Move cursor down
   */
  cursorDown(lines: number = 1): void {
    process.stdout.write(`\x1b[${lines}B`);
  }
}
</codeblock>
    <section><title>Rich Terminal Consumer</title></section>
    <codeblock outputclass="language-typescript">/**
 * Rich terminal output consumer
 */
export class RichTerminalConsumer implements StreamConsumer {
  private formatter = new TerminalFormatter();
  private contentBuffer = &apos;&apos;;
  private spinnerInterval?: NodeJS.Timeout;
  private toolsInProgress = new Map&lt;string, string&gt;();

  onEvent(event: AnyStreamEvent): void {
    switch (event.type) {
      case StreamEventType.METADATA:
        console.log(this.formatter.info(
          `Using ${event.metadata.model || &apos;AI model&apos;}`
        ));
        break;

      case StreamEventType.CONTENT:
        // Stop spinner if active
        this.stopSpinner();

        // Write content
        process.stdout.write(event.content);
        this.contentBuffer += event.content;
        break;

      case StreamEventType.TOOL_START:
        this.startTool(event);
        break;

      case StreamEventType.TOOL_PROGRESS:
        this.updateToolProgress(event);
        break;

      case StreamEventType.TOOL_COMPLETE:
        this.completeTool(event);
        break;

      case StreamEventType.TOOL_ERROR:
        this.errorTool(event);
        break;

      case StreamEventType.DONE:
        console.log(&apos;\n&apos;);
        console.log(this.formatter.success(
          `Complete in ${event.metadata?.durationMs}ms`
        ));
        break;

      case StreamEventType.ERROR:
        console.log(&apos;\n&apos;);
        console.log(this.formatter.error(
          `Error: ${event.error.message}`
        ));
        break;
    }
  }

  private startTool(event: ToolStartEvent): void {
    this.stopSpinner();
    console.log(&apos;\n&apos;);

    const message = `${this.formatter.spinner()} Executing: ${event.toolName}`;
    console.log(message);

    this.toolsInProgress.set(event.toolId, message);

    // Start animated spinner
    this.spinnerInterval = setInterval(() =&gt; {
      this.formatter.clearLine();
      const msg = `${this.formatter.spinner()} Executing: ${event.toolName}`;
      process.stdout.write(msg);
    }, 80);
  }

  private updateToolProgress(event: ToolProgressEvent): void {
    this.stopSpinner();
    this.formatter.clearLine();

    const bar = this.renderProgressBar(event.progress);
    const message = event.message ? ` ${event.message}` : &apos;&apos;;
    process.stdout.write(`${bar}${message}`);
  }

  private completeTool(event: ToolCompleteEvent): void {
    this.stopSpinner();
    this.formatter.clearLine();

    console.log(this.formatter.success(
      `${event.toolId} (${event.durationMs}ms)`
    ));

    this.toolsInProgress.delete(event.toolId);
  }

  private errorTool(event: ToolErrorEvent): void {
    this.stopSpinner();
    this.formatter.clearLine();

    console.log(this.formatter.error(
      `${event.toolId}: ${event.error.message}`
    ));

    this.toolsInProgress.delete(event.toolId);
  }

  private renderProgressBar(percentage: number): string {
    const width = 30;
    const filled = Math.floor((percentage / 100) * width);
    const empty = width - filled;
    return `[${&apos;‚ñà&apos;.repeat(filled)}${&apos;‚ñë&apos;.repeat(empty)}] ${percentage.toFixed(0)}%`;
  }

  private stopSpinner(): void {
    if (this.spinnerInterval) {
      clearInterval(this.spinnerInterval);
      this.spinnerInterval = undefined;
    }
  }

  onComplete(): void {
    this.stopSpinner();
  }

  onError(error: Error): void {
    this.stopSpinner();
    console.log(&apos;\n&apos;);
    console.log(this.formatter.error(`Stream failed: ${error.message}`));
  }
}
</codeblock>
    <section><title>Summary</title></section>
    <p>In this chapter, we built a complete streaming architecture with:</p>
    <ol>
      <li>
        <b>Streaming Protocols</b>
        - Event-based streaming with multiple event types
      </li>
      <li>
        <b>Stream Processing</b>
        - Producer/consumer pattern with async generators
      </li>
      <li>
        <b>Buffer Management</b>
        - Strategies for efficient memory usage
      </li>
      <li>
        <b>Backpressure</b>
        - Handling fast producers and slow consumers
      </li>
      <li>
        <b>Progress Reporting</b>
        - Real-time status updates and progress bars
      </li>
      <li>
        <b>Cancellation</b>
        - Graceful shutdown with keyboard support
      </li>
      <li>
        <b>Error Recovery</b>
        - Retry, fallback, and graceful degradation
      </li>
      <li>
        <b>Terminal Rendering</b>
        - Beautiful, professional output
      </li>
    </ol>
    <section><title>Key Takeaways</title></section>
    <p>‚úÖ <b>Streaming improves perceived performance</b> by 10-60x</p>
    <p>‚úÖ <b>Event-driven architecture</b> enables flexible stream processing</p>
    <p>‚úÖ <b>Backpressure</b> prevents memory overflow in high-throughput scenarios</p>
    <p>‚úÖ <b>Progress reporting</b> keeps users informed during long operations</p>
    <p>‚úÖ <b>Graceful cancellation</b> respects user control</p>
    <p>‚úÖ <b>Error recovery</b> ensures robustness in production</p>
    <p>‚úÖ <b>Rich terminal output</b> creates professional UX</p>
    <p><b>Next Chapter:</b> Conversation Management and Context ‚Üí</p>
    <p>In Chapter 6, we&apos;ll explore how to manage multi-turn conversations with context tracking, token budget management, and conversation persistence.</p>
    <p><i>Chapter 5 | Streaming Architecture and Real-Time Responses | Complete</i></p>
  </body>
</topic>